{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "““坚果改造笔画cuda_error”的副本”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiHanWang2Developer/data/blob/master/%E6%88%90%E5%8A%9F%E8%BE%93%E5%87%BA%E6%AF%8F%E4%B8%AA%E7%AC%94%E7%94%BB\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-UPaAdWoVgJx",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR",
        "colab_type": "text"
      },
      "source": [
        "# [How to train Detectron2 with Custom COCO Datasets](https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/) | DLology\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "This notebook will help you get started with this framwork by training a instance segmentation model with your custom COCO datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bVqmEoGK4jf",
        "colab_type": "text"
      },
      "source": [
        "本文参考https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVDC4G20IuIm",
        "colab_type": "code",
        "outputId": "9b9d1ceb-328f-4590-cf36-fa11f2881115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 10 09:49:13 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    62W / 149W |   3632MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "291391d5-8f6d-4134-898b-6b1ccd061d19"
      },
      "source": [
        "!pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git\n",
        "import torch, torchvision\n",
        "torch.__version__"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Collecting git+https://github.com/facebookresearch/fvcore.git\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-pz66wuxt\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-pz66wuxt\n",
            "Requirement already satisfied (use --upgrade to upgrade): fvcore==0.1 from git+https://github.com/facebookresearch/fvcore.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (1.18.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (0.1.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (5.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (4.38.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (1.6.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (7.0.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (0.8.7)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1-cp36-none-any.whl size=42662 sha256=30bd5ababf484cd1efb02b3cfb83ac9c268e966795c42c3704ce68a75b4240a1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qb12imrc/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n",
            "Successfully built fvcore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeejixTmwEmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
        "# clone the repo to access PointRend code. Use the same version as the installed detectron2\n",
        "!git clone --branch v0.1.1 https://github.com/facebookresearch/detectron2 detectron2_repo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "# import PointRend project\n",
        "import sys; sys.path.insert(1, \"detectron2_repo/projects/PointRend\")\n",
        "from detectron2_repo.projects.PointRend import point_rend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo",
        "colab_type": "text"
      },
      "source": [
        "# Train on a custom COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_",
        "colab_type": "text"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use [the fruits nuts segmentation dataset](https://github.com/Tony607/mmdetection_instance_segmentation_demo)\n",
        "which only has 3 classes: data, fig, and hazelnut.\n",
        "We'll train a segmentation model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that the COCO dataset does not have the \"data\", \"fig\" and \"hazelnut\" categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RhkndJ6JWqO",
        "colab_type": "code",
        "outputId": "0eb930ba-ec0c-440b-c8f5-9afac43f0ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # download, decompress the data\n",
        "# !wget https://github.com/Tony607/detectron2_instance_segmentation_demo/releases/download/V0.1/data.zip\n",
        "# !unzip data.zip > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW",
        "colab_type": "text"
      },
      "source": [
        "Register the fruits_nuts dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnkg1PByUjGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"fruits_nuts\", {}, \"./data/trainval.json\", \"./data/images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWknKqWTWIw9",
        "colab_type": "code",
        "outputId": "2f5a878f-6c4a-46a5-c7b8-1b6dc36f32d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# fruits_nuts_metadata = MetadataCatalog.get(\"fruits_nuts\")\n",
        "# dataset_dicts = DatasetCatalog.get(\"fruits_nuts\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/26 02:56:00 d2.data.datasets.coco]: \u001b[0mLoaded 18 images in COCO format from ./data/trainval.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI-aG4sj3cV2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "下面 笔画数据集\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Retbdmc07rgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"wz\", {}, \"./drive/My Drive/pic566_28class/images566.json\", \"./drive/My Drive/pic566_28class/images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttCvanr27rPN",
        "colab_type": "code",
        "outputId": "23e5445a-b115-4feb-9c61-2e237b91c82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "wanzheng_metadata = MetadataCatalog.get(\"wz\")\n",
        "wanzhengdataset_dicts = DatasetCatalog.get(\"wz\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/10 09:52:43 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from ./drive/My Drive/pic566_28class/images566.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E",
        "colab_type": "text"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q38FZu0W37T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #坚果数据集\n",
        "# import random\n",
        "\n",
        "# for d in random.sample(dataset_dicts, 1):\n",
        "#    img = cv2.imread(d[\"file_name\"])#!!!!!!!!!!!!!!!!!！！！！！！！！！！！\n",
        "#    visualizer = Visualizer(img[:, :, ::-1], metadata=fruits_nuts_metadata, scale=0.5)\n",
        "#    vis = visualizer.draw_dataset_dict(d)\n",
        "#    cv2_imshow(vis.get_image()[:, :, ::-1])\n",
        "#    cv2_imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5JPh6Ur8FTD",
        "colab_type": "code",
        "outputId": "20692392-eb97-4bf9-cd92-62cb3bdb2ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#笔画数据集\n",
        "import random\n",
        "for d in random.sample(wanzhengdataset_dicts, 1):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=wanzheng_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAA59klEQVR4nO29d4BcVfk//Dzn3Hun\nz2zvm91sNp0AqfQklAAKJCDNQEAQASlKkSYgwldBURALiAiCoYjSBaT3AAECqaQn23uZnd2pt5zz\nvH+cmcmmN8L+9OXzx2YyM/fcc5/nnKc/Z5CI4BsMHdhQT+D/7/iGAUOMbxgwxPiGAUOMbxgwxPiG\nAUOMbxgwxPiGAUOMbxgwxPiGAUOMbxgwxNCG6saTx44EKwEAhBwZAyAAVB8hIhABIgAA18kT2OLa\nL7744uud7D7EkO0Aikcg3AZ97djbTNEesE1ppV76/a0ht052ihyT7BTZKRD2UM3w68GQ7QAEciSk\nJGm6ZlgpZiaYJwiIqBuouQARHItIDtX0vjYMGQMACAAMl/uen19XWpSvcf7gE0+BdM445rDp0yZr\nGr/hngcbmpou/M63EqQ9/uZHAPCvn1961X1PtvX0Dd2cv3oMnRLW3RqD6QdN7OzpnXXeFUeec/lL\nCz6XBD2dnfMuuvSZV9+ad8JRRKD49D+MoWMA16XubmxonD514k0//N60/cdF4wkiePbtD3tScvny\nZWU5PkyLoP9lHgyhCAL0Btvb2r71gyuPPGjK9RfOW/DFMgCwbNuWEEk6jHFybCEl42nryNCHcrb7\nCEP6SMjyCgqaegaefeO9SDR29knHqXcRM/Yoifbu8OFTJwHAmGGl5QW5QzfXfYUhXlOjR4780+1z\nhSTLdn56958f/MVPiYiIOCJDAM31zmfLTph52FM/v+zL+pamzt6hmicRSSmllADAGHMcxzAMUC7L\n3gGHKik/eVQ12SbaqfhAZGBzWx8RAhzcPh/zBFB3QSB/i2u/fkdMSimEQES1PqSUmqbhIOzxyEMt\nVbnGt3oPAbwaoD+HhNjd8SaOGkX2PvDdiEgIEYkAAGoa9/uBcwCAzUmPus4CW/rtO8ZQM0AzDM7A\n3szh4giScc402H0GkG3LVKrM6/3TIYec+vbbX8kcEUAmEmJgADTtkRNPvGvhwpUtLSwQ4D7fFtJj\nD2zKIWPAF3+91W5bz4uq6cFL7lyNtqRsNKjci/OmVvOTr9f6WrBoOMw8b3cHR8YAkbndu/TtHQhh\nKUU0KgYGCMBkzHYcIWVSSlvXjWRSJJMsPx9dLkAE2yYpdzTUdjBkDCAixpggiOnBPCPSmdr0ERIR\n0zjfWjjtKlDTNF2/ZfLkAwKBbsv6yfr1Bbp+fVVVjq6bUv6yrq4hlbq1piYu5VivN1/X/9Dc/FZP\nD2fs+urqKaFQZyrl2PZza9e2dHbeduyxiqjjCgqK/vxnQjxuxIhflJcHXa4bFyxY2damhUJXHXro\n5EBAR3yqufmFeJwhXldVNTUU6jRNG+DFrq63w+FpodAVlZUccVUs9uvGRkvKFw888NyVK4fMEUNE\nBASAsLuwwLXZRwyBGN9LA6PS5Xqmq+uM5csHhDgqN/fG6urfNjae8+WXv29qun74cPWdfF3/werV\nV65d+6PKSpRypsdTAjD7n/+8/sUXJ4RCtmV91Ns74+mnZz799LvNzfctWaI4wRk77tlnb/7ww8sm\nTuwlOqmiItLRMfe11+a9//4pFRXlbveRubmlbvfpy5ffUle3v88HAC7Of15Tc+PGjd9dsUJj7NTi\n4uw8h3IHSJKI2OMtzdPXD/6IIQByItobDrSa5tp4HADWxOOlLtcBgcCva2vVRwbnagLvtbZabW1r\n4/H8cePMFSv2P/zwV9etG7CsHoAFLS1x27aFAIA5tbUTCgvPeOkldfl/6uoAYFl3d6XfL6ScVlIy\nvrDwuJoaYMxvGJVu94GBwNu9vZKox7I+j0YBoMrtbjPNxmQSAF7u6Tm9uPjJ9nY12pAqYQLG2JiD\nZqxatWBwvIEBSJaWP7vFBjlICttSquuF4+TpetS2z1ywAByHLEvGYjKZlDk58a4uq6/PJgKAPs6T\nUsYcJ7m55h+dm3vtlCmzX3hBZEa2hAAAQcQRAQARb/jgg8XNzW6vVyss5Pn5h4VCuzJbQcSGMBaE\niFzjUspgSaW++Sw0zoBrUkopdi8czRgjKWU8Lrq7yTRTS5aklixxOjv7OzubI5GZhmF2dSXC4XKv\ntx/RRBwQojeVGjBNAHAc57OOjhNrajSAco/niPJyD0C5rj80a9b1b78tUin/IGINVrXvNjefN368\nzhhJWeXzeThfFo0emZfHEPN1fbLfDwCNqVSpYVS63QDw7fz8LwYGAKDNNMf6fEMpggCAMYbeoDGY\nAQQcgZBLKXdXC1uWRckkRaN2bq4EGNA0CRAnAikvevPNO2fMuPCAAzTGnt+wYXF3d9poQeREiOgD\n+GDjxlnl5R/OndsWiy3v7Y17vcdPmVIWCt1x7LEAALY966mntr7pE6tWVQUC/z79dNS0Ptu+tr7+\nnb6+aaHQ0/vv32maqxOJmBCmEP9XX//r2lqlhJ/r6gKAh1pbb66pGTJPWL7zMHY3yoJhkFe+/qZv\n/6tpkxl6QhmWzbm0eMxE1tsEhdV45Pk7GGfKuFHZrBkRra5vUe5bdu9kHw8zac8KHTgAR0ACTgAI\nDmMOY3og5Arlm5yXBALz99vvB6tW9VhW9kaptWsH4nFz8+WvxGMOgLugADSNuVw8Px8AvJwnhMjR\n9b+PH7/FOFtgSKOhCv48NwNEJCDl6xcFPL4Dj4JUH+xKsEXYZGdsWAJSyWSiB2760e+feH5NQwtk\nyIQZvzXHA4hAADZ3S91tuF06IACgbjwwZUpA03TG/tbaugXVtrdOXQCaYaDXS4O+f8+oUQHOtznO\nFhi6lCSiJCmEAJfPwzd7H7gWcBto7YZ+QsaAG0A0pigXHAc07Y+PPS1i8ZE+A2wbiGzGvG5JBLaE\n+6ZgrwWlOf4DAw4dMBMmn0h97eiYMn8YP/oCxhgA3Apwa2ZwFf9ZPXPm6wsWbMy8yRAlEQKc7fGM\nmD8fIhFqadGGDcu/4ILBExs8zjYxlAwQUjqOo/tyPJwQWTrUJYkAmXDk7tg/pcUlf/rp5asb20eX\nF25sbLv5z4/f9/Mf//6ZN1bWtxw8vvaHs480OG9qabnl13d1RVJvdTMAWNKfWFWcP3v5ez7D44w6\nzBjoRERF/a2nCgCw+UdqQ4xE9FdVFZ52WvdDD8Gu7NetMGRWkJQSETVNI5ffqzHKABAEobRSOx9i\nc1SXFj7zwaLvXHl7NJE487jpAEBEeUH/hSdMv+R388++/YE17X3fO+1kGnT3xq7wg2uS4SXvul79\nPQIp6m+hFNOzAgDGBlNXic9JXm/VXXelUimGSES4Lf7tGEO2AxhjEhERiXGWfWwCQCBEcCz1Xykl\nZijiOI6u61LKba7T9t7I0g1NAPDKe5+ddfIxAICIE4aXDy8teuT6HwCApvEVS5dmvy+EAICElH9Z\n3HnNAQlX80pZULX1uI7jQGZ6mNHkAABEbsSQZemHH8453+Og9FAqYYYMOUeXmwZpOEQkQCcVZ5qO\nJFnmwRT14/G42+12HIcxtgUb0mxChCy9EBHZp6vrbnroGSJCImxcCgBSyuwyR0TGeXvcrm5fDxPV\nODSYlJxzx3E45/GlS+O6zqQkKQEAGSsD8E+b5goElOz6f5QBr722tKMjsvX7tLoZBvogyLFxATQM\nW9KnZk8ACBsC1qMbe6ISUlHuTfDnH2bp0jkYPboMkcrL8084YfIWA5YV5OxfU7kkHP72jGlL19TN\nOHgiAKyob7lu7rcrC/Oau8O6GS0sK2/b2MoYE4PcXQZU6pKycj+V8NoCKvdiNjRo0WhvlsSInLFy\nAO+xxwohdF2HPY1c7XMGdHREGhq6tn6fOpKYsCmRBHc3xn1dptZveSO2N2J7X25zedY0ayiBhISw\nDS2Zi5im6SedNPnII8dvvdwa2rtPnzn1Z2efWNfU9vTrzysG9EXjt/39hdt/cJqhcXLMux58FDe2\nZi9BRCnloUWaCJW6ykaqyM8WIyvZ0vLUU62aZpsmICpBL6Ws8fs9M2fquk5EexCIVvg6RBAReDxG\ncXFosH7DpEdGYg0J+dGCNUvXjxxwmJeZLm7nG7EKb2+3ySxJXh0TDjUlUBlIiMhY4IUXFh111H5C\nCE3bbPKOlD97+DkRDstUirndF9/9d/X+orX15/7qr+BY0LyyMwWkQkZqDoiFLjioQNNPuEzE+rap\nYBDRNM3k6683W5Zijro8oGlGIuGZOjV9yf+zOwAApJQFBf6zzz4MEW3b5pw3NnY/ueDN+f/pSTjo\nCvDTyps2xK2sI1blBR2h34ZcAwY01mZxIQQicK45jk/Fe7ag/g6QlumxsAmMQCBAlsRSiFOqvfyc\nO9AT0FMx0DRgLKsDZAYgpfzkk2YAIELOmZREVI4YPPxwbhimaXo8nj0mzj5nABEBqMXLTNN65ZUl\nf/jDq8uWNQ3PE5Xu9oFY95dtWlGtvTEBRGnlSUAsnSwAKUmZjIwFHSc3FPLOnTtz67u094TPvO3P\n27k7SClxoCdupQOaakAAOKiAe0qq+HGX0fvzs5dgRo0r6jPGEosXJwESjCGRUuCc8wIh/Mcfv1tL\nYZv4OnYAIqZS9t13v3Tvva/btpWbC6nUCj3mcB2U+SwBGCJl6EWEWsbcQ8aIgozl+/3+m246IRgs\naGrqUYUh6sk/f+Dn0NUARdUqc9n397/bDQ16dXXueecJIRQFnaaVdOPB96zRRcb+QcSQBjNLNHHl\nExKAb2XXZg0bKWXHSy91ZPZE2lQgGunzGUccoWnaNlX3rmOfM0AI8fbbX37xRV1BgWFZXX19beGw\nWklSuYHqAbLuDiJKIJ2hRNacCLWl8isr826/fd5ppx3KGHv00Q+UVtymKzAYivRSSsdx2CdP1Qmv\nkJFsCFYIMbvKw06+hldP0DSNAAgIM1cNlkJCCOuddxpNkzI3RQAfgGaa3kmTHMfZy8zdPmfAE098\nuGTJRqLutrbO7JrK+pySAAAlEGa6MyRRt+WtiwWaEjmH1tDfLp0246qf2rat1jvnnDEOu+D0q12C\niAxRvDt/YVMfIlMSQ0q5fw4WFBZqp96Usm3GmBQChGAZ0aRUkeM4lmUZnIslS9oZE46j3ueMVRlG\nYMYMAmB7XZi1zxlQURF8/32byNC0oJQWIhHZUsqs2YCIJNEm3pH099veXitQ5EoeM9J+/scHj/b0\n89Ji27azfqb6d1e8HiXohRCw7I14pLc1iUIKtScCGhxfYbAr/2FJ0jRNCIEAJEllILIyinOu63rz\nq69GGUtmqrLU4NUej/fYYweXyO0x9jkDFiz4S35+qr8/LgQRkXLsAdjSPiVPiQDuXo+CkKMw0PEw\nYUl6p8nz3k2rQIpbzr9c1r2vyAEA2/TptglFHSGEeOLGjzosyhg/UspThnvpuEuwdipnLJVK6bpu\nrVsHdV86nibfQWdyvz/LXZlKxW65ZaPjQDbSQAREJaZpzJix9/IHvh4l7PVOyMkZH4s9DYPDAFZK\nCoeAC27wRMSmjIkCaEtkDjAOJGRjZwq94d2+ZdaGWf+J1bZuRYQAURXCHFJk5BYU8zNuVSqacy6E\n6LvnHijykW20/7W26O67A2eeyTkX0WjjnDnt9fVLEUVGOgFihaZBfr577FjDMLYXmNp17HMG6LoG\noOk6d7n0zT5gDggAroHbR3ZvzJYyE+fSGRicmI7AWHWJB6uLthizpCRnu/fLRFUty9J1PfrYDZ90\nCaZpKvaQZ8D0QtBufBFcbpQyG+exCwr7+zvWC1ev9E+4+OLAxRczywKiVo/n1USClPRTcRLEGoCS\niy7SNG3HwcFdxD5nQDDoAfACjHa7bwDwIt4LcC6RF50miP0JfOeAUUFe7jPbI22/1N3jQ2U3kNWo\nu4ejeSPYdP63KmHmzF2/XbZ4ljFmrV+kNS5Z0pc2HjnDU4bpqTk3aPnVXsaUPlAWUdFVV+q/vqW7\nz/ww4qwFMISwGZOIMpmUREzpfESGyAGqpXR/5ztKKqo9tDf0+XryAUhkId7H2ErEoxEXId4DFAc+\nCgAAGqnjx1wvRub3F14Qbrwq1v5L1Ir3QLhm3AgiImmZsXvO+aQXBKQjGYfmo7t8pH7S1ZzzbJRf\nqQpXXl7g9NNrEX2IQsoEoi2lGosrPiEq36xa09jw4UZ1tdo9ymbdG9J8TQkZxDYAIIpIeQjRLICf\nEN+fWB4AALQBgLS7GfMj90rRQ5QCp4UgHbdRtnz2ORXtbNtWOnbwXbJklVLKv1/V3960sMtR/630\n80OKDe8NzxlutwrfM8bUC2XG+KqrXNOPOESJQSJkTIWdJaUDJMgYItYSlV1yia7rQojBHsMeY0ci\naL8xE4Szt42idc0bfT7D583xu1PcsBDfINkl7CWaGUEpmL/Gtk2dgCHTuI4y6TJKmIyCVm712Sid\npqVt7Z1Leuoj8XBiUyULQvmEEt2jIWJ5T1dpzqbkpRCCiPw9S6xljz/baCHjRFTmwdPLQbviMSev\nQskNHGQEc86Bc2C8eO7ckme/KI7HuxCVGlc8V146AtRqWonPV3DhhUJKXdf3sjNAYUcMEI7M0fJ+\ndNh1t7557Z7fgQgkEIGwBGMEaDPtIM17LLot0XcPEZEjVd0CA0z2PBqsuIvsFnK6HNsBx1n7Xt3C\n1gXMwIQZz7gO5DY8a9+vqz28unB4XkEqRYMYoGkaml362r8/3cZt4IyxUkOcXgmpC+73TD3ZpVzZ\nrQLOgCiBQNPybrhh0m23vS4lDZIsahN4EA+Rsva558jt1jnfS+Mni11SwtzYCz2DGE8uiSeX1FSO\nkPIjABDiHQDQzAiCJZP/IlcOISU6fuEQak6HaD5H5y4q+4uVsDmKSKyvMbHBjJgAaUNEkmTI8gL5\nznvC7XdBcLNlSFY8p+Wfy3tYS8wGgHJDnFrJUhc9FDryLNg825V9raL5JAkRh11xRf8dd+SbZk9m\nwKyuPsowgnPnGgcdlH1ncFptj8mzcwYwxs+benFVoLbfivx91b0BPfSdkWf79YAlrKfXz+9KtH93\n9PdTTrIyUB3QQy/XP7O853NEdkrt2SNDYyJW+Jcv3hS3Y0kn7g1tVq2PUV3akjEwWFwA+bjkCOid\nRjkXSfQkeh9zZEICNYQ3Ng1k6mqUIQ4ICFa/GQzm9ndEITCoflQK7xf3dfc7dT22BBruw1MqMHXJ\n/OARp2EGkPHIBkshUHEeRHC5vJdeOvHee9+0LFSKl4ghHkBUlJNT/pvfaJqW9cP3Xv7sEgOKfCX/\nWPfgU7H554y9ZELBpKnFhz27/rHuZGdVoObU2rPvX34XAASNnHuX3VnkLf3+uMuX93w+IX9Svjv/\nN1/8LKAH/jL38afWzV/e8/lnn32mAkEqIEPvPiLa6yKtAz314WDbBzok1scLmhMxU/6KMUYBQhxG\nktpTlF1uRMQZ9zJ/dXBEyJ8zekZNybBiZq4BACmlY1n6s7c5kdblzSkArPHByZXM/NGToUPmqDjS\nTumlblF9/fXx3/3OjZgEAEQPY9MRi4qKRr39tisYVHp77+mexc4Z0JPoao01AUBrtCHXlV8dqD13\n7A/VR5ylfasvw0uJZGe8NWAEAWB4qHZZ1+dEcsDq39i/NjuUaZrSobaVHfWLWpIfrKSeThtMqYu2\n3hJbWiosiuiFQcTqs3Xd0JnkuXp+nrcgxHO5hx1w8tgTf3zM8lfWDHTEABABJREt+rf9yp/er0tx\ngmIfTargyR8/lXfobNjlpaoUMoZC1kEH1X722SrGCqU8GjHv7LPL7r7bHQrtpcm/TeycAY5MV15K\noIDmS4rE3Ytv2/I7m8402eajkp103vvrJ+s/qu9a1wsuistoXVvvgBNzpCNJGnqZaZkI6epEnqlN\n92vBHD1vfCDfq/kDw93jjx417aRJgUIfACBHXddVRQsAyL52/aWf/LNJ6JYcn4/D86Fv/0u1NT0D\nGx8TjsO31VA3GEbzAkz0kLclts5CxkLjxk375JP9ET2cu88+OzBtmvnCC1ZGWG2bSh0dO6XkNrF7\nnnDSSYZT3QcUTlnW/TkAlvkq2uIqVbeZM1Lfv2Fq8aEfNb5nOJ6awKh3lr7R0xx++8kPOiKtrX0t\ntrAg/TBpiS5JYqZhVudGrpGf587P0fJ1P/cM146ce8TYw0d5fZvSfpukMKCQUtop/sb9nw4YkWTi\nlEryenOiNXOZE5LNzRYiIu7UlOZ9vcyKiAQIsxkR88rKnAsuIEQMBLjXK1taHE1ToSTYqm5lL7Fd\nBojtdCj+Y81D3xk575jKEznypT2L2uLNm02IIN6beLfxrYop1T+ddkdPvKu+d31vvCduxT6r+0hV\ncBCRpmvCEasi72tM2aCEwDQGLk2CxTYmDM3NPX4vF4ZcFXjm549v/cyff/65esFIso/+2dEfi0Sc\nc4dJecBZVukMjamq5x2t2cHgvJklCL0FRmk1ACBjelVV1qfjiJwxJciQMaUrsrG5zahZUrLTe22B\n7Zan27a9/5gDhC24zj0hd/aW2QIFdaGwpJW0rKRtpxzHdACAkCQIkJRyUj5X4HenP3Dds5f1JcIH\nFR+BDJX7johAsKb/HRcnjaHOha45DKUQ8MrTD5172U19KSQE5AZ58re53L744osl/14ZaRsY3ftE\n2fL7BhzQA/nsW5cZxdVZPQ8Z6T/y/BtsucOOV+kAEXAdXL6tPxRSmLYJAJxzl+ba4tPs9HSuB7Y6\n3GvwhLf5/i6JICmkYwopJQkiSSRJONJK2o7pEBEwAISUlZQkCdJe1e2n/N5vBDSm/evz+ZFkOJ1L\nQs4Y83JfrpEf0HLqYx8H3REAciQkbXAIUPltjgmOBN27K4vX8hbT9HO9gJBbBiREx0bOOJBEtklh\n2rbp5EPeLeXdlzdufyRCQHLMwXXoKTuVsBKWbTHGQAIh6Zoe8AT0jPUBCAW3Fgw8OmDV7agGfQfY\nEQP+/qsn1rxb17Wh14yZTtAGRoSK3BTuD3f2tQ/Y/Y60lWevtoUkyRgDghc+ejq7aaYUHIaAea6C\nHCOv0Fui61r5pOLDTpv28WVPsHiMgN9z63Wlxfmcs98/+JSUcPLsE489Ygo3XNf/9pHGsHPRqTMT\nKfvx/3wEAP/6zaVX/fbJtu6+bP2E7S6EsRWUyY0wxpAxEAI437RTuYaMENClu2BQaHmzaipEQoaa\nS9E9norHzTgCMmBgg8w0fAgSYSfsNty5vlyNZU4rYHuuEnakA9a+W1/3SWN7qrU5WWfaJlMV5EBS\nyE3GDqkqEkZEgICU9i0ZMgDwcG+OnhfUc/LdhVoeO+y0qWNn1uZV5yizhCGC7jtyyrjOnt5zr/w/\nAAj4vTf96HtdvX1zL7zqjNNPP2fOUb985I0tJkabt0rEyo+gGWOlbXPOVZxH6UqpMouMIQC6/490\nGzWef3UV1RBGEP4MFCI4CzCAYAE9RtiB9jw7FU2x4SyQG3AedGJvxgio4uoK/yS/3WmTQz2v9Fgd\nVtX1VYCAHD3DPcnvJTWu+Q7xBb8fZH4GjwOsB2AApwCMAtAA30f6YEfh0u0yQNf1ykklHRu68roK\nulPtNrMRMJvPklIqj1Std5VuRUBgwBn3a8FcV36eu9Cjuysml447qnbs9JG+XK+ikaqrEUIAInBj\nY0PDlZd8/8Yff++tBYs+W7IKAF55dyECralrPOrwqZuRXgU7B69aSPNbcVQIYdu20jEq02IYRjZE\nyks5PAzwKMBFQBMJDgN4AmSHTJYn+el83TXrKlOVzM/qLqszyo2aO2t63+jNmZljFBur5q3ScrVx\nT4yDVyCxJrH6/NWIWHZpWXRRtLW9dZwzTjLZ+9Pe4NRg4KQA/B7wMKQkwa8ANKDrCFYB9MD2sF0G\nOI4TyPcfeNK41rp2bYHWHmtpjterj1R/LxEhIKRL55mORp5RENJz81wF4JPjjhk5/qhR4w8dI6RQ\nyXEVAbYsSxEF02dTsuaWtm+dc+XMwyZff8m8BZ8tA4BYkplJT98ASmK9vclYzLJsJxxOEoHOtL5I\nsrc3+cgjS5qXtSf6kt7ccLuuH3987eTJkyljn2QtC2U4tje1QxuEzwpTK0mS8HMAAP4uJ5sAYPgN\nw1FHaUpyqO+TPuGIZENSy9UAwD/BH343DARO2Il+Ec0SJ+eoHO9I74afbAAAy7H63u9jwESDgAIA\nABpHVEE4CQGAPIRFuCcMUIuIcTb+8NEn/OSo+y+bX9BYXBddGzZ7GLCskAGEAqOo3Fvl0by+Kteh\np06tmlZeOaJcFU6pvCDLpJ+EEC6XCzOHvgAAERQWFNZ39D/3yvsDA4mzTjkWABCZKQzLIUlkmk59\nS88xh4yNRFJjh5dVluZ1d8Xb26MPPrh4TJlPJG2PKTs6YnIQsgrp9ddfP/PMM/v7+5WrAQCOdIgI\nJaKGICHVkAKC1eetVg8CANLakc+g5uwe7i49v3Td5etIECKChGQiaTiGFJIYpd3JfyKsVKPuRD1s\nlwGapnHOGbJkJNX4Wdtx845qXd3uftndn4jE7GhKJoQUXs2fY+TqmrHf8aMqxpX5fF7OedfycGRN\nTErJOLMtm2cit0p8KEmlFImVcJCcEfuN+OOv5zmCHMe58c4H/vLraw2GEhhJQoBk3HrsuU9mz5z4\n4RM3fLa8fl1Dh7Bt27JXrWhetkSbMal4WMANGenkOE4qlcqENFBKmUgkksnkYDcFJIAEcEBYgvu4\niAkA8NR6khuSaRNDS68/0CG2OpY/Kz/8WljL0QKTAuE3w8zHht86vOGXDU5kU+NGurwpcxe2itF0\ngjUAArAYKUJg7j4DxowZG4skpcjkoYCUDnAsR9giLXyRGEfDbeCDCADnfvsKIlq0amVnuFfXtOkT\nJ3tcbsRNM8sNBqeN309dK6QgKUHKjz5b8d6CK5NO2mqcfvKlgjRLBj5e2nj43LsYYxzF7IvuUltG\nmS86gwLWbuq+Nz+V84r92SJOn8933333FRcXM8buueceIjrrrLNmzZrFOf/uOd+ti9b97OafxWKx\ne/52DwAs/s/iUy48pbmjuea3NeF3w8mWJDL0urz+gnRZSlVRVXxp3J5sj3t8nN1pJ9clZVzmHJFj\nlBhV11ep2a4+fzUBAQNd0zfl7D4kyAe4CQgJogD3b5f6O2KAbTu2cDa122Z0X0HZFbGBf9tWk5DE\nGQKAJKk+jFgxIcQHSxd7NA0529jacvz0w/JCoXQcmMDLPbllIcVLApXkY0A6YkpQuuwSETrjflsg\nR/Lolu2A0rtZ6qupJJwEYynOguG4DYAqSHn44Yf39PTMnTsXAAKBwM033xwOh4899tgzzjjj6h9d\nfdHFF6mVlF68QFa7lWpO1V1cl+vPHVs21v2MGwAoRIwxuALygnl5kNf2ZFvzPc3MxcY8OCZZl4x+\nHg2/li6TQURgsOG6DaW5pRIkRQlvxPT8XgB4YefyZ0cMAADN4Iwxw9AGpWPBtB7S3WB4PFkvOru/\npx6zX0NDq9utm1afdCgUyv/P+x/88IdnHnDA6Pb2btO0q4aXT5wzPlvHsXzYLyHSgOTUvfSrx5Y5\nisYGxz8sPMeR0ULfgEfvWtHNVCsASYJ0fB45D3amFJH52ImlkBFBdXV111577c033/zmm29++umn\nAPDyyy8DwOLFi0855ZR0i1eWdgC6pnsMz+jK0dl3smn9LBEKbyrMc+Uhx/b57U7Y2UQdNZoBNUU1\ntrAtuQ8cMQBwu0tzcm4GaASoAmgjehjgx4jPADQCjAM4CUAD6CF6BMA855yTHn74eSlTUiYBIBJp\ncbv9Dz749LXXnj9sWFl9fWuGYYNyUgDkKynyUvqRAAhAY8IWYAlX3CoSQgfQbZsD6AAG514inXNn\n9OiCigrvgQdWa4POPGtsbDzjjDOmTp16ww03LFiwAAAsywKAQCjgD/iHjxiel5sXDAQnHTiJiIKB\n4OjRo4PB4Oeff55V3Zsmhulair+8+ZebH7w5sjYCBFCTnqSmaQ45fAT/xZm/uObUa+a/P7+xp7G6\nsPr7R33/K2YAACCWEj0GsAHgXMSZkA4H+QG+DfB7ABPgOMRZAP8xDOPddz9lbJPYSqViiMk773xw\n3LhRs2YdsnUlNxGB7nPpzODSFqjM/L7U457gSZ2pjnh8OQAgEmOg61zTmGFwl0sDwJ4e6OkB1fTo\ncmn33+9BxIKCgv7+/ldffbW7u3vevHnZuwgplNBrbW2dOXMmAIwdO7a8vBwzJdBbBPppUHW08js2\nsYcAGSIiK2XnzDjn6lOuVtUVDLdsGtxF7JwBRL0AGwAA4FOAo9JUg+EApQDXZgapIyIp5cKFS1Op\nWPYZiAiRUqnOVaswHO6/6aaLsg+TfiQiIgnIGaZdLElUFohCAFnuMZp2ouUsMoyxRDpRfyLxdCh0\nl21/iJifTD7sds9BzOG8xHFeUTMcOXLkVVddJaVMpVLXXXfdQw89BIOkCkP2zjvvzJ49+6mnnvry\nyy+bmpqyz6i8k+yXs+KIiIQU6fezKgiAvOTP8//u/N/B5vJqHzGAtoiJISIRAqwGeGjwm6ZpdXSE\niRzVS5JeMUSIYFkDHR1si0IaxQDhCEy/Tg8VcpnkZyA+AVjqCvwNcT1RJ+Iwj8eD2KPrbwBc5PF4\nAEYA3A9wQrY++eOPP164cKGUcmBgIJlMTpkyRUmSZcuXnX3O2YyzVCp16aWXbrFUlX+efYrBT5T9\nZjonmtkNUASP/PgRr9urlv+uEntb2PmuYawAoAYAAA7KbAVArAcYAaCqNl2IxQDw9tufIirqZ60V\nIiJN04iMkhJVhjWobQiRMaZp2uAH37ScKA7gAPiIViI+B3A/IkLaot6udaHGzDZtZZen2HE4eitQ\nphvJtm11Bkh2c6AfC3MLZ0+evXWv8h5gV3ZAO8BMgO8RtSG+D7A/ABBFAf4OcEFmhBcBOn/3u4eJ\nUpBuQSEAKmKGm2nd0ltZkHPc/qM6Fn6xTk+fZsIYC0aXaXano0dyhaxgLourfAMApKRpgWNJkWDs\nC4IaoEIAIRLzNZ/txPvVX+ZZi3gqskqRWkRO//MPPESGjpbt9A3AfiPeePSfjmMrUy0WtIePHjNq\n+JjcBKBlQ2//4JqqDU/+e9sMEEJK6ty4zLCcSuYCABXCiuTIi6pP3PDkvzHTxtTZuCSc6PR4+za0\n5+6YmJ6igvKjD9tdBkjEh2GTuXl3ZlWtBfhV5jtARAsXrkC0EVUbNAFgn+ySkrkQB/r1p95eo+va\nY6+4stFgHeJANqGuS+eWiYaWDuoSADjxl5FsQN3su33wZIR1Z/Yv4XpuTCTZ5SRWA0gzHEGPWyaS\nqboW/4jKqqphnfWNkoiAbMaj/WFDdzvRHkqknJaOnSYasuZod1OzSFl+ZqgCd8fgKa99JNTGm9sZ\nQ0SGCGZvn2VFzaQRZ207pecW+Gqqo4koEhmQUldlmUpJMMaERATMYZR0bGnbmteDmo8hU6lgFCkk\nSchBYoKESZg9s4lxjiAJOWfb7z+hL6X5JQBwQwMAV14OuAzyuHVHslgiZ1jFxo116numFHYs4vX5\nWdAEl9tNDLK8zqQGtoZqyeNtfgcpJtP5hqhfTPOOLaqq0TQuiRgiMuaSuUbCcnlzfZVl25tsqqtX\nmNuISGyXAT//+d0NDa3V1eXnnTcbYPY2v6Nat1SWcfTobwOsU9TPFF9yCTjZ5793yqxP+zon5RR3\nW/GfLn3vxLEHnlhQpSO2mwO/bV9kcY0i0CbNeHrbwOcXgzzp12ygCXKq4cDztjfDLTAwMKDm4/P5\nHMcRDQ0t77ypMtsICGYSEEPjRuq6npOTM1h2y0GtYbC5DQoAWtdrAyudAemoQLrm1r41Z27t7DmD\nC4SK3+9LdjUUF1XXzpyzveltePLf8eZt7I+92gFElEql3G73a6992NLS4TgJzPTgMcaE8OUa/Qbi\nMF/o8iXvXj/w4f2Tjjy0oPzVNcuf5ct95SUX5FUeGxr2UrQV0idYfQXI5sWIKD8/v6urCzKquH5R\ny7K+1Qk7PmDFBjfXqYOJKPu7TRnpo4aKrIpPEFMwCKBhiHLyB4oiz1v3rvkry6TpeZBFy3a/hyeD\nvWKAqmQyTfOaa+4UIjrYviTS/X5faV6RQdiWjDXEIhriioHeEo+/zBe4ctSUkO72adriZBdiG22j\nZmcP+UFEQgghRCwWq6io6OrqYoypaFW0OxbtjQ+kBiLJvsHmporyEUnYTDCp7kEKhHP3S03Ms/OD\nTq6DtkUp/UtvOBqFcgFAiAi5wAr2/Ljw3WbAYENePepzz721cWOzlMmsoaZpGpH/r3/9v1/ccAUy\nJhh6Cguc7l4k0Bnesf+My794c100fPbwUVNyS8y+AQMBARiyQfZeJlCx+0U4ysWrra2NRqNLliwB\nAHIIAKSXXNzl9/tYHmR7NFSyCABAgoyDjIMTcWQUnKiUUQILCll5zImmKBmW6wUIZMiJVzbVBP1+\nvYIjoe7nwSI3AJTk7HZNCuwBAwYvc5fL1draefnldwgRyTZGA4Dj6LW1ZbNnH/XLn6avYi7NU5Sv\nuXRDkJ/r3WaCIc4qrumx4mYspnnopBH8lXrRlwTItEgQEWU603dreoq4jLGCggLVAMMSjIggAEFv\naPiw6oknjBvoiEdaBnqb+zo39PQ19fe19MfCcXAR6JRwEh3dbSak4lYsYcc55yp8K4RAhgjINR7B\n3kNbZlaWVecNC+WUBafOPGB3yZjFbjNABd+z/v1ll92eTPZJaW0qSkCOGHj22XtdLhdkhItSeprX\n4zJcD9Qte/qQOWE7tTLaGdANU8r+sNa5MXjxpL5V3fhWowBIC2JJu310qOM4pmkqDSmlzMnJ6e/v\nVwnRvnUDjfWddsJ+8zcL0A1g0EByIDzQGzMHEk485SQJSdd127Yho0V0XVe5ZUc4yBAImMaEIxKU\n+KRpgZ1wpp154LZ+AWE3sIc7QDHgmWfeeOONDwZLf8YYYznXXHP+mDHDVVVap5X8wcaPlVR5orsh\nNzeIQXx13QfJjm7usolLzsDtkksiTvtHoYNHpq48KMkQRKw920i/61Bet+oeVXuxoqKir69PeUx9\nG6NSyAiGl3QuIiBASFdRZGQRAEgpDcMQjlChb3VemSTJGXdpLh1dOuiaZhjc0JkBBI7t7O4kt8Ce\n7ABVfNDZ2XPJJb+w7T4lc3VdBwDHMSZMGPOzn12S/oWPzFXZV2pluQvztKDfbqtHsm2QyKkoJCSI\nj5tYWU+gIkQy9kbJYVP1IJim6XK5ttYE21QMg9eB4zilpaXDhg1bsWKFaoVkHkZJko5AjkgopEgn\nLwFVnMdghgvdLuY23C4dDYMbGupuzeNz+dFhoEkyJPPC6ANHefM9wSKfSJCmaXtTFAR7ZgUlk8lA\nIHDZZb/SNEeI9H63bRtAc7tDTz752x0X0auPNJehV5Q7A/2yLwKSegd0RwhkrDMiv+zQqlpbOxa3\nFcxIVo3+LhnGYDt9p325Ksyg63ogEMjLy4NMwFlzMxETmjCqPSN1rjPgHLmGmtfjY5KBRGBEXAYL\ngt6Q2xUw3AGX7tU8QU+oIOgLeQbncwCAJMVEQjpyV9JeO8CeMMDn8z3++Esff7w4mexQJZhEhMjc\n7uIHH7ytvLw4S6Dn77g73tzmqyz70KSGhtaqqrLzzjtZfeQ4jm3bpmli0nz5gqsTi1ettqJtTpIx\nTiQR7YBm7Ld+UeHDx064+sLqs+cEcnOzgkURdHs8ztZOE5HP5wsEAslk0rbtP7z/q8Mqj0o5iUUd\nCxlDZMgYA4ZcY4wxZBmfuHPrIekvP30ka+MpkaWqC9IVaXuBPdEBDQ2tl19+u5QRIlJiFAAZyz3/\n/JPnzDlyBydpDH5f0zQlWJjXO+epB5reWoBX3FqWjK8w+y0AAIw69sL+riDTwr+9b/WfH538syvK\n58wiRHW8hq7rSsptfYvsdlHmUFVV1erVqzVN0zzc5dcnlRwxoeZAzvi6nlUj8kYb3LWic4npJGfV\nnri2Z2VZoPLRpQ8cUDJl/5JJ4UT38NxR9356JwDklAYHp8yyAQwE9Bdso55317FrxbkZE1MVC51+\n+pWW1U+UVF6PlKRp+aeeeuxdd12rrIidyh+FbCRd1/VRJ86qmnnoCz+8ruC9z1ZbsRYy1e0GpP1+\nX1s15SduvTtw1wOTb72q/PiZGU9bZHXP4GWYte4RMT8/f/jw4atWrSIi3aPpHq0+tv6zrg9/sN8V\n1Xk1a8MrHbJGl4xZG1nZlmz8uOed03LPLSksnj7iqL99+ScXd40uHq9a2yadvN+e0Xen2A0GqMV1\n++1/Xbu23nGiAKCeU9cLZs8++tFH71RlWLvuN2UzHlJKXdfB7zvz8ftaP1viuuTG8vaOFXY0KmwA\nZIw39vc1DUSqY6HYlbeGykqm/PKa8ukHQ8Ymzq76wfaMmnBOTk5JSUlVVVVdXZ26V9KJK5Urid5o\nelHNZETOaFNYACBJaFynrygusivYJQYoowIA7rnn0d/+9m+pVBfn6Qc2jIJZs46YP/8OxpjX64VB\n63rHoE1d16h0uFInww6ZcsanLy24/Q85Dz21zhyoc5KSVMUtNsT7G2KRkWZ04HtX548fNflnV+RN\n2k/Z6WopqB05MDCQvYXjOKFQ6Oijj66trX3rrbcYY5BJzHzc/u53R5+ftBPt8dZes3vw3D7r+PDM\n0ef1JXtNJ7lrZNxz7OoOAIC//OWft9zyRyHCmsaEEJxzTcubMePg5577I8/8KovSCruolwZnRZRA\nV1tNM4zpt1zdMuc4fvnN5fVNy1L9AxoxhrbtIMK6aF8d6x+9ItX73ctcRfmTr/nhsJOOYbqmjp/J\n2GPpaasDBYQQI0eORMRP2xco8fW3L/8IAEu6Ps1OZmNkLQA8t+EJAHBz94AZyXHnftT+7q6Tcs+w\nXQZIKYk2Hej26KMv/OQndwnRC5A+3ZTznEMOmfz00/coX0Y10A5Oau8Y21QG2RGklMMmTjjjvWc+\nufdh7+/+1mTGN8ikkyntl0Cro72rCUqiPeFrbsu56TdjLz67et4pYGiqEpIydSWKK2VlZeouWwSc\nt4e2WEtbrGUHX/gKsaMdoIwtInrttQ+vuOJOx+lFFACgaS7OgxMn7vfss7/3ej1K6+7YNNwtpCux\niDjnh/74B2NO+dbrF19f9uX6ZclIF1mImP6RBqBOstoHOkPIu+7726o/PZJ31CHTrr8sNKY2qwyU\nUFKz+uSTTzIpaPhKztn4SrATEeQ4znvvLTrrrOsABhT1iTwAgWuvveiqq+b5/T5lh9BX10GofKis\nzUdEBVWV5775r/Uvv8kuvanHTKy0YkmhUv/pDRqRzoe9rV6uj3zjna63PvKPHjHxJxdWHnMEIKoN\nsVlTwv9j2FF/AJGsq2u58so7pey3rJgQXNNCEyeOfuyx35SU5Hu9HsjI8cEMyL7eM9CmgiKkzO+W\nEtGIbx9dvnzaqz+6qeDNj1ZZ0VayEbOZEwDApBTLoj1fIhu2NNJz0fpAMFQxZ9b4785xjRimghnq\nvETFgx04K18ztssAxnhnZ+9jj73EecI045yH/H7/3Xdf873vnar2tcpEulyurJEKg04F3mMMjjqo\n1AJkDFbD7/vOo39qWPCpc95V5bHYSiceJwFAUlI2QihANolUfX+iIB6ueOQf6x971u3xFB992KjT\nTyw8aKLudilzS0qpjGa1LRR79nLme4bt3jUajc2f/6JtW5wzxvKPPvrgE0+cKQQ+/PBzGesFMRNQ\n3B7dOz9ZbIYjrrp2qh6293NVbmDloVPOWvzaR7f/Ie+JF9eZ0XqZAiYzgl7ltoAx1ivscLJvOWAo\noZc+92L9a+96JBRNP6jmlOOHHTvdcac1v1pGu3L3faQztsuAYNA/cmRFKpXKy8s95JCJwaCvqysM\ng+vzAHZq74S7I1Z/1BCQV1K8o+/tAmTmzFVE9AUD02+7JnHBWa+c++PShpaVIt4rTUw3PWLGNQMp\nCUD2SRlxzLVWzJBU/trr9QsXeS6zQqOGF884uHzmwcUHTRSGrkbOZuO2SNkrVmXXWVZC7uUTKWyX\nASUlBVdffT4iCiEZQymJ880sh10x6TwdnSYHV15OcXW5GnOPJ6rsFp5pPjUMw6itPvXdpz+99+HA\nH+fXQ2wjpRwmlXjMFrEBpOcopUgSrU9FN5gxDTFvRd/w5sbcJ57VE2befqMLj5haPWt63sT9UNt0\nnJyCElnqvpZlpUtxv6LTmmAHnfJfCVQthq+yrHbudus19gzZ5DsAxDu6n593mbmmbqUT73RSaq1s\nbvBgZn+oh0XOGeea4zguznOA5zNjWDDXSJgQ9OWPqgmMqPKPqMqtrfZXV/iHlZPGDcNQvidkAieq\nCS7rJ2WCkptcGcr0bu6YFEP9i9p7BCUusr1gWm5w3ltPLXz4H/ov7+1Mxlc5cYu2MDezywyzFavp\n0k+SnVJ0SXttJIlE7q6eQG+bd+HCXI833x/gpq2lLHC7ghWl3pIib3kxL8wrrB3uKSn0lRV7SgrB\n7VLeT9Zsy4oE9UsJW9x+a/xXMkCtMvXXcRyPx8M5P/zCcyaeeuKCG+4ofOntVXashTYL42xBgoyk\nIiFk5lMiohhgQtpSpjCWoKhqLiVPknsHOo0vwQ3MbxhlhUXMkcyyecrSDN1TVOAuLvSWFfkry3xl\nJd6yIndxoa+8GIP+rA+YVTCUOdM0O5P/SgbAIDs126KNiJ6c0Kz7fx2+aCWcdWlZpH+lE0tCepcI\nIYlkRhClc/6wye0AIYgxlJnze6XM9qVBXDoJ1d+KiKnk8qYIY1x5oJpJen+HdyN3ERYGQwWhHHQE\nM21mWrquh0bV5O0/Jm/C2ODoGiuRFEJuvRX+WxmQhWJANhoIAAWTJ8xb+uaC2+7Oe/T5DU6izkkQ\nKK2grqBBfwEGbQ51TKXcLMmebVrCzSUMMYaOY1uSiCgCBID1vQnW16FG0DTuZlroi+7AF4tChrvI\nF9CT1ugL58JWe3HIfklvXwAzZ9JxQz/8tmtOeOsfVSWlh7lyQkwnUr+Etz1ZvFObcjPTiEh5f+oo\nCuBc0zTOmPqRMWIMhRAWyZhjW0RCSmE7IKWdTNFW7VD/9TtgC2STPJqmucaNOufTlxf+4cHAn59o\nMGPrrJggGExr3HReyk5NwU3Gd/akJiXZB6cq3ZznMj2EWhC1Yt0tDD1v4vjKmQdXTT+kZ8VqqytM\nWxUV/E8xIFsXrP5rWZbX55tx3eV9Z5688Po7Kj76fI0ZbZabfqVSqXEVeN8BMAMiQkyHvNKxL0k+\nwjxuhFArMNxe5IkcX9WRhxZMOaDmyMNyKsvU6QyO4/Sv3WgS8a3Omv6fYsAW/pE6W55znjOs/NjH\n/9j84Wf6T34xort3Q2qgExwBpBwCKSXnmhDO4GuVZoZ0RdOmMBcRuZkWJMxhegi1QrfLMnQ+omLU\n8UcVTT2gfMoBustlWZbb7bZtW91dqWtkjDHErXrK/qcYsDWUvFDJomFHHFSz+LXljz/ruf/RA5o6\nWu1kO1k90lYpsy38+ax1RAQMKYcZeajncKPI5eFCatXlhQdP9IwdMWnOt7VQIFsUqwZRAcpsdG/H\nru7X4Qlzl8tdlL/v7rIjEACAOscr7bVKSQBWf7Txw097P1tG8WSvY6pOpuxF2Vorr9vjAjQcwfw+\nb1WZp7KsbP9x3pIiIYTqkEFEKYRqFZNSKqWstpQ61AeIlAhTHTJD4wkL09xmc8jXhs1VZfpF5cQJ\nlRMnpHojrYuX0+aJGkQkSUTSGwwGK0q9pUXM0BEZEZEjEq0dAGQO2iUq8JcRgCoiS4MS3jvCvmWA\np2jPo29fD/zDygsmjofNBYXaAbZtM84ykXe2dxWIaWxNkH0rgv6LsDUdsqefZbEv7vsNA7aLwXGb\nfZe//B+3gvYG+3Thb7rLNztgaPE/FQv6b8Q3DBhifMOAIcY3DBhifMOAIcY3DBhifMOAIcb/B2k4\n9p7k4IohAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F911D6A50F0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA",
        "colab_type": "text"
      },
      "source": [
        "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the fruits_nuts dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from detectron2.engine import DefaultTrainer\n",
        "# from detectron2.config import get_cfg\n",
        "# import os\n",
        "\n",
        "# cfg = get_cfg()\n",
        "# cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "# cfg.DATASETS.TRAIN = (\"fruits_nuts\",)\n",
        "# cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
        "# cfg.DATALOADER.NUM_WORKERS = 2\n",
        "# cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "# cfg.SOLVER.BASE_LR = 0.02\n",
        "# cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough, but you can certainly train longer\n",
        "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\n",
        "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # 3 classes (data, fig, hazelnut)\n",
        "\n",
        "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "# trainer = DefaultTrainer(cfg)\n",
        "# trainer.resume_or_load(resume=False)\n",
        "# trainer.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEuB2wY_8kCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "\n",
        "# Add PointRend-specific config\n",
        "point_rend.add_pointrend_config(cfg)\n",
        "cfg.MODEL.POINT_HEAD.NUM_CLASSES = 28#修改POINT_HEAD.NUM_CLASSES为28 默认值为80\n",
        "\n",
        "# cfg.merge_from_file(\"./drive/My Drive/Colab Notebooks/detectron2_repo/configs/COCO-InstanceSegmentation/Base-PointRend-RCNN-FPN.yaml\")\n",
        "cfg.merge_from_file(\"./drive/My Drive/Colab Notebooks/detectron2_repo/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"wz\",)\n",
        "cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "# cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "cfg.MODEL.WEIGHTS = \"https://dl.fbaipublicfiles.com/detectron2/PointRend/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco/164955410/model_final_3c3198.pkl\"\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.02\n",
        "cfg.SOLVER.MAX_ITER = 800    # 300 iterations seems good enough, but you can certainly train longer\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE =256   # faster, and good enough for this toy dataset\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 28  # 28 classes (heng,shu....)\n",
        "# assert cfg.MODEL.ROI_HEADS.NUM_CLASSES == cfg.MODEL.POINT_HEAD.NUM_CLASSES\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVtTbR_A-WBq",
        "colab_type": "code",
        "outputId": "79c24162-e2e1-4e45-f993-f03fa26f4b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#正式训练\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/07 16:58:41 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): PointRendROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=29, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=112, bias=True)\n",
            "    )\n",
            "    (mask_coarse_head): CoarseMaskHead(\n",
            "      (reduce_spatial_dim_conv): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (coarse_mask_fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (coarse_mask_fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (prediction): Linear(in_features=1024, out_features=1372, bias=True)\n",
            "    )\n",
            "    (mask_point_head): StandardPointHead(\n",
            "      (fc1): Conv1d(284, 256, kernel_size=(1,), stride=(1,))\n",
            "      (fc2): Conv1d(284, 256, kernel_size=(1,), stride=(1,))\n",
            "      (fc3): Conv1d(284, 256, kernel_size=(1,), stride=(1,))\n",
            "      (predictor): Conv1d(284, 28, kernel_size=(1,), stride=(1,))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/07 16:58:41 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from ./drive/My Drive/pic566_28class/images566.json\n",
            "\u001b[32m[04/07 16:58:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 566 images left.\n",
            "\u001b[32m[04/07 16:58:41 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/07 16:58:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.53 MiB\n",
            "\u001b[32m[04/07 16:58:41 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[04/07 16:58:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "'roi_heads.box_predictor.cls_score.weight' has shape (81, 1024) in the checkpoint but (29, 1024) in the model! Skipped.\n",
            "'roi_heads.box_predictor.cls_score.bias' has shape (81,) in the checkpoint but (29,) in the model! Skipped.\n",
            "'roi_heads.box_predictor.bbox_pred.weight' has shape (320, 1024) in the checkpoint but (112, 1024) in the model! Skipped.\n",
            "'roi_heads.box_predictor.bbox_pred.bias' has shape (320,) in the checkpoint but (112,) in the model! Skipped.\n",
            "'roi_heads.mask_coarse_head.prediction.weight' has shape (3920, 1024) in the checkpoint but (1372, 1024) in the model! Skipped.\n",
            "'roi_heads.mask_coarse_head.prediction.bias' has shape (3920,) in the checkpoint but (1372,) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.fc1.weight' has shape (256, 336, 1) in the checkpoint but (256, 284, 1) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.fc2.weight' has shape (256, 336, 1) in the checkpoint but (256, 284, 1) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.fc3.weight' has shape (256, 336, 1) in the checkpoint but (256, 284, 1) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.predictor.weight' has shape (80, 336, 1) in the checkpoint but (28, 284, 1) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.predictor.bias' has shape (80,) in the checkpoint but (28,) in the model! Skipped.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/07 16:58:41 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[04/07 16:59:02 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 19  total_loss: 4.955  loss_cls: 2.646  loss_box_reg: 0.944  loss_mask: 0.684  loss_mask_point: 0.640  loss_rpn_cls: 0.052  loss_rpn_loc: 0.073  time: 1.0535  data_time: 0.0171  lr: 0.000400  max_mem: 2482M\n",
            "\u001b[32m[04/07 16:59:24 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 39  total_loss: 3.170  loss_cls: 1.058  loss_box_reg: 0.923  loss_mask: 0.602  loss_mask_point: 0.506  loss_rpn_cls: 0.022  loss_rpn_loc: 0.065  time: 1.0645  data_time: 0.0084  lr: 0.000799  max_mem: 2482M\n",
            "\u001b[32m[04/07 16:59:45 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 59  total_loss: 2.552  loss_cls: 0.822  loss_box_reg: 0.832  loss_mask: 0.478  loss_mask_point: 0.349  loss_rpn_cls: 0.012  loss_rpn_loc: 0.072  time: 1.0617  data_time: 0.0092  lr: 0.001199  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:00:06 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 79  total_loss: 1.992  loss_cls: 0.598  loss_box_reg: 0.658  loss_mask: 0.352  loss_mask_point: 0.298  loss_rpn_cls: 0.009  loss_rpn_loc: 0.057  time: 1.0645  data_time: 0.0089  lr: 0.001598  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:00:27 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 99  total_loss: 1.629  loss_cls: 0.465  loss_box_reg: 0.540  loss_mask: 0.282  loss_mask_point: 0.262  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0596  data_time: 0.0085  lr: 0.001998  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:00:49 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 119  total_loss: 1.434  loss_cls: 0.406  loss_box_reg: 0.473  loss_mask: 0.251  loss_mask_point: 0.261  loss_rpn_cls: 0.008  loss_rpn_loc: 0.063  time: 1.0609  data_time: 0.0087  lr: 0.002398  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:01:10 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 139  total_loss: 1.306  loss_cls: 0.348  loss_box_reg: 0.405  loss_mask: 0.232  loss_mask_point: 0.244  loss_rpn_cls: 0.006  loss_rpn_loc: 0.056  time: 1.0621  data_time: 0.0088  lr: 0.002797  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:01:31 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 159  total_loss: 1.281  loss_cls: 0.346  loss_box_reg: 0.413  loss_mask: 0.212  loss_mask_point: 0.238  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0624  data_time: 0.0085  lr: 0.003197  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:01:52 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 179  total_loss: 1.145  loss_cls: 0.287  loss_box_reg: 0.370  loss_mask: 0.195  loss_mask_point: 0.218  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0605  data_time: 0.0086  lr: 0.003596  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:02:14 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 199  total_loss: 1.077  loss_cls: 0.305  loss_box_reg: 0.364  loss_mask: 0.191  loss_mask_point: 0.202  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0618  data_time: 0.0095  lr: 0.003996  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:02:35 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 219  total_loss: 1.233  loss_cls: 0.298  loss_box_reg: 0.376  loss_mask: 0.203  loss_mask_point: 0.202  loss_rpn_cls: 0.008  loss_rpn_loc: 0.061  time: 1.0614  data_time: 0.0087  lr: 0.004396  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:02:56 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 239  total_loss: 1.195  loss_cls: 0.346  loss_box_reg: 0.351  loss_mask: 0.187  loss_mask_point: 0.224  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0607  data_time: 0.0087  lr: 0.004795  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:03:17 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 259  total_loss: 1.126  loss_cls: 0.347  loss_box_reg: 0.365  loss_mask: 0.195  loss_mask_point: 0.182  loss_rpn_cls: 0.010  loss_rpn_loc: 0.060  time: 1.0610  data_time: 0.0089  lr: 0.005195  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:03:38 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 279  total_loss: 1.084  loss_cls: 0.275  loss_box_reg: 0.367  loss_mask: 0.168  loss_mask_point: 0.207  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0596  data_time: 0.0086  lr: 0.005594  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:03:59 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 299  total_loss: 1.067  loss_cls: 0.278  loss_box_reg: 0.346  loss_mask: 0.165  loss_mask_point: 0.196  loss_rpn_cls: 0.008  loss_rpn_loc: 0.059  time: 1.0592  data_time: 0.0087  lr: 0.005994  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:04:20 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 319  total_loss: 1.015  loss_cls: 0.253  loss_box_reg: 0.358  loss_mask: 0.141  loss_mask_point: 0.171  loss_rpn_cls: 0.006  loss_rpn_loc: 0.066  time: 1.0588  data_time: 0.0084  lr: 0.006394  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:04:42 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 339  total_loss: 1.004  loss_cls: 0.263  loss_box_reg: 0.342  loss_mask: 0.144  loss_mask_point: 0.175  loss_rpn_cls: 0.009  loss_rpn_loc: 0.060  time: 1.0602  data_time: 0.0080  lr: 0.006793  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:05:03 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 359  total_loss: 0.982  loss_cls: 0.275  loss_box_reg: 0.346  loss_mask: 0.148  loss_mask_point: 0.161  loss_rpn_cls: 0.004  loss_rpn_loc: 0.064  time: 1.0592  data_time: 0.0101  lr: 0.007193  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:05:24 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 379  total_loss: 0.914  loss_cls: 0.229  loss_box_reg: 0.356  loss_mask: 0.137  loss_mask_point: 0.176  loss_rpn_cls: 0.006  loss_rpn_loc: 0.054  time: 1.0597  data_time: 0.0090  lr: 0.007592  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:05:45 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 399  total_loss: 0.866  loss_cls: 0.205  loss_box_reg: 0.307  loss_mask: 0.127  loss_mask_point: 0.160  loss_rpn_cls: 0.010  loss_rpn_loc: 0.068  time: 1.0599  data_time: 0.0087  lr: 0.007992  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:06:06 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 419  total_loss: 0.993  loss_cls: 0.220  loss_box_reg: 0.347  loss_mask: 0.131  loss_mask_point: 0.174  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0577  data_time: 0.0096  lr: 0.008392  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:06:27 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 439  total_loss: 0.899  loss_cls: 0.195  loss_box_reg: 0.330  loss_mask: 0.133  loss_mask_point: 0.169  loss_rpn_cls: 0.009  loss_rpn_loc: 0.061  time: 1.0586  data_time: 0.0088  lr: 0.008791  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:06:49 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 459  total_loss: 1.033  loss_cls: 0.278  loss_box_reg: 0.349  loss_mask: 0.139  loss_mask_point: 0.185  loss_rpn_cls: 0.010  loss_rpn_loc: 0.064  time: 1.0588  data_time: 0.0087  lr: 0.009191  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:07:09 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 479  total_loss: 1.007  loss_cls: 0.280  loss_box_reg: 0.345  loss_mask: 0.133  loss_mask_point: 0.162  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0581  data_time: 0.0079  lr: 0.009590  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:07:31 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 499  total_loss: 1.044  loss_cls: 0.275  loss_box_reg: 0.362  loss_mask: 0.122  loss_mask_point: 0.162  loss_rpn_cls: 0.009  loss_rpn_loc: 0.060  time: 1.0588  data_time: 0.0085  lr: 0.009990  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:07:51 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 519  total_loss: 0.906  loss_cls: 0.223  loss_box_reg: 0.291  loss_mask: 0.108  loss_mask_point: 0.158  loss_rpn_cls: 0.011  loss_rpn_loc: 0.077  time: 1.0570  data_time: 0.0086  lr: 0.010390  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:08:13 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 539  total_loss: 0.921  loss_cls: 0.252  loss_box_reg: 0.334  loss_mask: 0.121  loss_mask_point: 0.162  loss_rpn_cls: 0.009  loss_rpn_loc: 0.069  time: 1.0572  data_time: 0.0094  lr: 0.010789  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:08:34 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 559  total_loss: 0.856  loss_cls: 0.171  loss_box_reg: 0.318  loss_mask: 0.112  loss_mask_point: 0.170  loss_rpn_cls: 0.007  loss_rpn_loc: 0.046  time: 1.0569  data_time: 0.0092  lr: 0.011189  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:08:55 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 579  total_loss: 0.861  loss_cls: 0.208  loss_box_reg: 0.315  loss_mask: 0.121  loss_mask_point: 0.150  loss_rpn_cls: 0.008  loss_rpn_loc: 0.056  time: 1.0577  data_time: 0.0084  lr: 0.011588  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:09:16 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 599  total_loss: 0.851  loss_cls: 0.185  loss_box_reg: 0.302  loss_mask: 0.116  loss_mask_point: 0.146  loss_rpn_cls: 0.011  loss_rpn_loc: 0.059  time: 1.0573  data_time: 0.0089  lr: 0.011988  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:09:37 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 619  total_loss: 0.903  loss_cls: 0.226  loss_box_reg: 0.327  loss_mask: 0.113  loss_mask_point: 0.153  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 1.0570  data_time: 0.0086  lr: 0.012388  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:09:59 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 639  total_loss: 0.901  loss_cls: 0.229  loss_box_reg: 0.353  loss_mask: 0.114  loss_mask_point: 0.160  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0576  data_time: 0.0090  lr: 0.012787  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:10:20 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 659  total_loss: 0.900  loss_cls: 0.239  loss_box_reg: 0.342  loss_mask: 0.111  loss_mask_point: 0.152  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0572  data_time: 0.0095  lr: 0.013187  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:10:41 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 679  total_loss: 0.819  loss_cls: 0.172  loss_box_reg: 0.304  loss_mask: 0.095  loss_mask_point: 0.144  loss_rpn_cls: 0.009  loss_rpn_loc: 0.058  time: 1.0575  data_time: 0.0083  lr: 0.013586  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:11:02 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 699  total_loss: 0.925  loss_cls: 0.227  loss_box_reg: 0.360  loss_mask: 0.106  loss_mask_point: 0.151  loss_rpn_cls: 0.008  loss_rpn_loc: 0.065  time: 1.0575  data_time: 0.0095  lr: 0.013986  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:11:23 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 719  total_loss: 0.850  loss_cls: 0.203  loss_box_reg: 0.318  loss_mask: 0.110  loss_mask_point: 0.163  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0573  data_time: 0.0079  lr: 0.014386  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:11:44 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 739  total_loss: 0.844  loss_cls: 0.192  loss_box_reg: 0.310  loss_mask: 0.105  loss_mask_point: 0.154  loss_rpn_cls: 0.007  loss_rpn_loc: 0.059  time: 1.0564  data_time: 0.0087  lr: 0.014785  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:12:05 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 759  total_loss: 0.865  loss_cls: 0.181  loss_box_reg: 0.329  loss_mask: 0.101  loss_mask_point: 0.151  loss_rpn_cls: 0.008  loss_rpn_loc: 0.070  time: 1.0564  data_time: 0.0089  lr: 0.015185  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:12:25 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 779  total_loss: 0.874  loss_cls: 0.193  loss_box_reg: 0.325  loss_mask: 0.107  loss_mask_point: 0.152  loss_rpn_cls: 0.010  loss_rpn_loc: 0.057  time: 1.0550  data_time: 0.0101  lr: 0.015584  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:12:47 d2.utils.events]: \u001b[0m eta: 0:00:01  iter: 799  total_loss: 0.924  loss_cls: 0.246  loss_box_reg: 0.337  loss_mask: 0.105  loss_mask_point: 0.138  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0548  data_time: 0.0087  lr: 0.015984  max_mem: 2482M\n",
            "\u001b[32m[04/07 17:12:48 d2.engine.hooks]: \u001b[0mOverall training speed: 797 iterations in 0:14:01 (1.0561 s / it)\n",
            "\u001b[32m[04/07 17:12:48 d2.engine.hooks]: \u001b[0mTotal training time: 0:14:04 (0:00:03 on hooks)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF",
        "colab_type": "text"
      },
      "source": [
        "Now, we perform inference with the trained model on the fruits_nuts dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM6RCjvB9vU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"wz\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO",
        "colab_type": "text"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM",
        "colab_type": "code",
        "outputId": "be854aa4-05bd-4abf-ba6c-a1ec09a844ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        }
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(wanzhengdataset_dicts, 1):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=wanzheng_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels用于实例化可视化的不同颜色模式  IMAGE_BW：与IMAGE相同，但将所有不带遮罩的区域转换为灰度。仅适用于按实例绘制蒙版预测\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "    #如何输出单独的mask\n",
        "    masks= np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks) #[n,256,256]n为笔画数\n",
        "    for mask in masks:\n",
        "      mask=mask.astype(\"uint8\") #mask从[false,flase]到[00001100]\n",
        "      mask=mask*255       #变成二值图\n",
        "      cv2_imshow(mask)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMwAAADMCAIAAACwQNulAAAr90lEQVR4nO2deZycRbX3T1U9S3fP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\nFpmm4PwvkCLegFhUDAsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=204x204 at 0x7F911C97B080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAABcElEQVR4nO3Zy3KDMAwFUNPp//8y\nXXXRCY/YkrDTOWfHIka6NmBIawAAAAAAAAAAAAD8T9vsAjrsfw9zSv9KGeUR+83xmA8K4EVKAh9x\nCZx3Gi//OzxCsZyFfm7hFfBe69EG1gygZ9qDHawWwN7a1rnqYy0sEkDoSg/1MDWArBtcpIl5AfR3\nf35tBLp4PoDxad8qNgRPBjDU+m+BNz9eOICxGT+o63qg0UbyAwje2a4Kuhp6TgDJ+9TbYgoSWOdd\nYNLzaJEA5j2NpwfwdutFj4GJAaTO+vBgkwLorrdqGzAhgKFaa/YArT0eQMnNLjTogwEE6qzYAeX8\n/O2dUOg8lR9F4yPcZhA+RcVbcOYYpfWdnyBp9IR7wPFr+iLf2m4VzVJm+7Xxrj5R5Ytr8QAO+k+u\nePrLUKf0CVv73+GXBbD4ggUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAPgBoEMoTpLJqT0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F911C97B048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAB30lEQVR4nO3by3LCMAwAQLvT///l\n9FCGQiEQsGXLzO6lPdCMJEtKeZUCAAAAAAAAAAAAwGeqswN40Xb62S3utQqwXfzeKfKvPpeZYNue\nP+aAhTrgNuEewa9QgAdH3R5+6gIcaPLm+NMW4PCEN2aQswAv7be2FL6b/rqvPmv9RRk64Fjidfdh\nTTnML8DD9K/CC6lAvgKcI9puYwsoQaYdUEr5TWUrpY7aCLk6oN459fuPvPFuIqmeC9QJ55FgBGrZ\nfhv/SfYxM5GiA2otpXUa3y1PigLMNH8JHvXkiD9iCTZ4+yCXKcDjBni/kRcZgaD+Lylug63aznCN\nDthvgM99RehSzBPhbpcIt5N/n9BX3QHdDm6B2+C9BujXuOlHIDb9/AW4k3/fkJMXIObtsMjrdRWf\nfu4lOCL/pW6DId2auAN2Xy/vKu8O+Jd/VKBrjEDgMaUdgVHvlGYtwFX+kXOadAcEfBxsR84CXOQf\nHWDKERiYf8oCjMw/YwGG5p9wB/zlPyS2dB0wOP90BTjlX0/vGMdLVoDz+Q8bzWQFOBm4mbItwa3k\ni2moKZ8WBZhn8tpL8H9Ap69/AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nZPYDReU4YGNbf8IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F911C97B6A0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLH2qPSMgOSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "outputs[\"instances\"].pred_classes\n",
        "outputs[\"instances\"].pred_boxes\n",
        "outputs[\"instances\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bo0cypwllj",
        "colab_type": "code",
        "outputId": "a59ab3d3-0cc7-4c54-d3fd-219f98528d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "wanzheng_metadata"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metadata(evaluator_type='coco', image_root='./drive/My Drive/pic566_28class/images', json_file='./drive/My Drive/pic566_28class/images566.json', name='wz', thing_classes=['piezhe', 'heng', 'hengzhewangou', 'pie', 'na', 'shuwangou', 'henggou', 'shugou', 'hengzhegou', 'hengzhezhezhegou', 'hengpie', 'shu', 'shuzhezhegou', 'dian', 'wangou', 'ti', 'shuti', 'shuzhe', 'wogou', 'hengzhe', 'xiegou', 'hengzhezhepie', 'hengzhewan', 'piedian', 'shuzhepie', 'hengxiegou', 'hengzheti', 'shuwan'], thing_dataset_id_to_contiguous_id={1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvn2tueICLiE",
        "colab_type": "text"
      },
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API. This gives an AP of ~70%. Not bad!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Y_TQ6YCOWT",
        "colab_type": "code",
        "outputId": "d81020aa-1eb6-43ef-88a5-97b0a2e16c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"wz\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"wz\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "# another equivalent way is to use trainer.test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/07 17:16:09 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from ./drive/My Drive/pic566_28class/images566.json\n",
            "\u001b[32m[04/07 17:16:09 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/07 17:16:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.53 MiB\n",
            "\u001b[32m[04/07 17:16:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 images\n",
            "\u001b[32m[04/07 17:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. 0.3023 s / img. ETA=0:02:49\n",
            "\u001b[32m[04/07 17:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 28/566. 0.2937 s / img. ETA=0:02:40\n",
            "\u001b[32m[04/07 17:16:23 d2.evaluation.evaluator]: \u001b[0mInference done 45/566. 0.2978 s / img. ETA=0:02:37\n",
            "\u001b[32m[04/07 17:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 61/566. 0.3017 s / img. ETA=0:02:35\n",
            "\u001b[32m[04/07 17:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 77/566. 0.3030 s / img. ETA=0:02:30\n",
            "\u001b[32m[04/07 17:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 93/566. 0.3052 s / img. ETA=0:02:27\n",
            "\u001b[32m[04/07 17:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 110/566. 0.3045 s / img. ETA=0:02:21\n",
            "\u001b[32m[04/07 17:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 127/566. 0.3041 s / img. ETA=0:02:16\n",
            "\u001b[32m[04/07 17:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 143/566. 0.3044 s / img. ETA=0:02:11\n",
            "\u001b[32m[04/07 17:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 160/566. 0.3039 s / img. ETA=0:02:05\n",
            "\u001b[32m[04/07 17:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 175/566. 0.3066 s / img. ETA=0:02:02\n",
            "\u001b[32m[04/07 17:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 190/566. 0.3085 s / img. ETA=0:01:58\n",
            "\u001b[32m[04/07 17:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 205/566. 0.3098 s / img. ETA=0:01:54\n",
            "\u001b[32m[04/07 17:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 221/566. 0.3102 s / img. ETA=0:01:49\n",
            "\u001b[32m[04/07 17:17:25 d2.evaluation.evaluator]: \u001b[0mInference done 237/566. 0.3103 s / img. ETA=0:01:44\n",
            "\u001b[32m[04/07 17:17:30 d2.evaluation.evaluator]: \u001b[0mInference done 254/566. 0.3098 s / img. ETA=0:01:38\n",
            "\u001b[32m[04/07 17:17:35 d2.evaluation.evaluator]: \u001b[0mInference done 271/566. 0.3094 s / img. ETA=0:01:33\n",
            "\u001b[32m[04/07 17:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 288/566. 0.3085 s / img. ETA=0:01:27\n",
            "\u001b[32m[04/07 17:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 305/566. 0.3075 s / img. ETA=0:01:21\n",
            "\u001b[32m[04/07 17:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 321/566. 0.3078 s / img. ETA=0:01:16\n",
            "\u001b[32m[04/07 17:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 337/566. 0.3078 s / img. ETA=0:01:11\n",
            "\u001b[32m[04/07 17:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 353/566. 0.3081 s / img. ETA=0:01:06\n",
            "\u001b[32m[04/07 17:18:06 d2.evaluation.evaluator]: \u001b[0mInference done 369/566. 0.3086 s / img. ETA=0:01:02\n",
            "\u001b[32m[04/07 17:18:11 d2.evaluation.evaluator]: \u001b[0mInference done 385/566. 0.3086 s / img. ETA=0:00:56\n",
            "\u001b[32m[04/07 17:18:16 d2.evaluation.evaluator]: \u001b[0mInference done 401/566. 0.3086 s / img. ETA=0:00:51\n",
            "\u001b[32m[04/07 17:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 418/566. 0.3083 s / img. ETA=0:00:46\n",
            "\u001b[32m[04/07 17:18:26 d2.evaluation.evaluator]: \u001b[0mInference done 435/566. 0.3076 s / img. ETA=0:00:41\n",
            "\u001b[32m[04/07 17:18:31 d2.evaluation.evaluator]: \u001b[0mInference done 450/566. 0.3082 s / img. ETA=0:00:36\n",
            "\u001b[32m[04/07 17:18:36 d2.evaluation.evaluator]: \u001b[0mInference done 465/566. 0.3090 s / img. ETA=0:00:31\n",
            "\u001b[32m[04/07 17:18:41 d2.evaluation.evaluator]: \u001b[0mInference done 481/566. 0.3094 s / img. ETA=0:00:26\n",
            "\u001b[32m[04/07 17:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 497/566. 0.3099 s / img. ETA=0:00:21\n",
            "\u001b[32m[04/07 17:18:52 d2.evaluation.evaluator]: \u001b[0mInference done 513/566. 0.3103 s / img. ETA=0:00:16\n",
            "\u001b[32m[04/07 17:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 529/566. 0.3104 s / img. ETA=0:00:11\n",
            "\u001b[32m[04/07 17:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 545/566. 0.3107 s / img. ETA=0:00:06\n",
            "\u001b[32m[04/07 17:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 561/566. 0.3107 s / img. ETA=0:00:01\n",
            "\u001b[32m[04/07 17:19:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:57.964124 (0.317227 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/07 17:19:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:54 (0.310668 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/07 17:19:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/07 17:19:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[04/07 17:19:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1fa900de22ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./output/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minference_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# another equivalent way is to use trainer.test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/evaluation/evaluator.py\u001b[0m in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator)\u001b[0m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;31m# An evaluator may return None when not in main process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# Replace it by an empty dict instead to make it easier for downstream code to handle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_box_proposals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"instances\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Copy so the caller can do whatever with results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36m_eval_predictions\u001b[0;34m(self, tasks, predictions)\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coco_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoco_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpt_oks_sigmas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kpt_oks_sigmas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 )\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_results\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# cocoapi does not handle empty results very well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36m_evaluate_predictions_on_coco\u001b[0;34m(coco_gt, coco_results, iou_type, kpt_oks_sigmas)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mcoco_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0mcoco_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoco_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;31m# Use the COCO default keypoint OKS sigmas unless overrides are specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36mloadRes\u001b[0;34m(self, resFile)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading and preparing results...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unicode' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ6lYrCqLLLW",
        "colab_type": "text"
      },
      "source": [
        "## Benchmark inference speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxRHYcAC_Z0f",
        "colab_type": "code",
        "outputId": "3ad8069b-efd1-4d61-c5f5-e290e562cfdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = predictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average(sec):0.30,fps:3.31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFMOqBbWEh5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}