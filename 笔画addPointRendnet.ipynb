{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "““坚果改造笔画cuda_error”的副本”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiHanWang2Developer/data/blob/master/%E7%AC%94%E7%94%BBaddPointRendnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-UPaAdWoVgJx",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR",
        "colab_type": "text"
      },
      "source": [
        "# [How to train Detectron2 with Custom COCO Datasets](https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/) | DLology\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "This notebook will help you get started with this framwork by training a instance segmentation model with your custom COCO datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bVqmEoGK4jf",
        "colab_type": "text"
      },
      "source": [
        "本文参考https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVDC4G20IuIm",
        "colab_type": "code",
        "outputId": "55d1bea9-b508-4260-ddad-88921bedd477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar 30 15:51:55 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git\n",
        "import torch, torchvision\n",
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeejixTmwEmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
        "# clone the repo to access PointRend code. Use the same version as the installed detectron2\n",
        "!git clone --branch v0.1.1 https://github.com/facebookresearch/detectron2 detectron2_repo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "# import PointRend project\n",
        "import sys; sys.path.insert(1, \"detectron2_repo/projects/PointRend\")\n",
        "from detectron2_repo.projects.PointRend import point_rend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo",
        "colab_type": "text"
      },
      "source": [
        "# Train on a custom COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_",
        "colab_type": "text"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use [the fruits nuts segmentation dataset](https://github.com/Tony607/mmdetection_instance_segmentation_demo)\n",
        "which only has 3 classes: data, fig, and hazelnut.\n",
        "We'll train a segmentation model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that the COCO dataset does not have the \"data\", \"fig\" and \"hazelnut\" categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RhkndJ6JWqO",
        "colab_type": "code",
        "outputId": "ccde48ba-621e-4613-9829-b1c07d6b3bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # download, decompress the data\n",
        "# !wget https://github.com/Tony607/detectron2_instance_segmentation_demo/releases/download/V0.1/data.zip\n",
        "# !unzip data.zip > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW",
        "colab_type": "text"
      },
      "source": [
        "Register the fruits_nuts dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnkg1PByUjGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"fruits_nuts\", {}, \"./data/trainval.json\", \"./data/images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWknKqWTWIw9",
        "colab_type": "code",
        "outputId": "2f5a878f-6c4a-46a5-c7b8-1b6dc36f32d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# fruits_nuts_metadata = MetadataCatalog.get(\"fruits_nuts\")\n",
        "# dataset_dicts = DatasetCatalog.get(\"fruits_nuts\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/26 02:56:00 d2.data.datasets.coco]: \u001b[0mLoaded 18 images in COCO format from ./data/trainval.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI-aG4sj3cV2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "下面 笔画数据集\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Retbdmc07rgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"wz\", {}, \"./drive/My Drive/pic566_28class/images566.json\", \"./drive/My Drive/pic566_28class/images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttCvanr27rPN",
        "colab_type": "code",
        "outputId": "533d34b2-7b79-470e-d4ef-b343d345a9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "wanzheng_metadata = MetadataCatalog.get(\"wz\")\n",
        "wanzhengdataset_dicts = DatasetCatalog.get(\"wz\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/30 15:53:56 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from ./drive/My Drive/pic566_28class/images566.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E",
        "colab_type": "text"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q38FZu0W37T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #坚果数据集\n",
        "# import random\n",
        "\n",
        "# for d in random.sample(dataset_dicts, 1):\n",
        "#    img = cv2.imread(d[\"file_name\"])#!!!!!!!!!!!!!!!!!！！！！！！！！！！！\n",
        "#    visualizer = Visualizer(img[:, :, ::-1], metadata=fruits_nuts_metadata, scale=0.5)\n",
        "#    vis = visualizer.draw_dataset_dict(d)\n",
        "#    cv2_imshow(vis.get_image()[:, :, ::-1])\n",
        "#    cv2_imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5JPh6Ur8FTD",
        "colab_type": "code",
        "outputId": "83f9bd1b-0843-4222-a5c1-c1154ff46668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#笔画数据集\n",
        "import random\n",
        "for d in random.sample(wanzhengdataset_dicts, 1):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=wanzheng_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAvJElEQVR4nO19eZxUxRF/Vfd7b+7Z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\nnwtgiOlzAQwxfS6AIabPBTDE9P8A8Pe6pmT28zUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F6D3057C668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA",
        "colab_type": "text"
      },
      "source": [
        "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the fruits_nuts dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from detectron2.engine import DefaultTrainer\n",
        "# from detectron2.config import get_cfg\n",
        "# import os\n",
        "\n",
        "# cfg = get_cfg()\n",
        "# cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "# cfg.DATASETS.TRAIN = (\"fruits_nuts\",)\n",
        "# cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
        "# cfg.DATALOADER.NUM_WORKERS = 2\n",
        "# cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "# cfg.SOLVER.BASE_LR = 0.02\n",
        "# cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough, but you can certainly train longer\n",
        "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\n",
        "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # 3 classes (data, fig, hazelnut)\n",
        "\n",
        "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "# trainer = DefaultTrainer(cfg)\n",
        "# trainer.resume_or_load(resume=False)\n",
        "# trainer.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEuB2wY_8kCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "\n",
        "# Add PointRend-specific config\n",
        "point_rend.add_pointrend_config(cfg)\n",
        "cfg.MODEL.POINT_HEAD.NUM_CLASSES = 28#修改POINT_HEAD.NUM_CLASSES为28 默认值为80\n",
        "\n",
        "# cfg.merge_from_file(\"./drive/My Drive/Colab Notebooks/detectron2_repo/configs/COCO-InstanceSegmentation/Base-PointRend-RCNN-FPN.yaml\")\n",
        "cfg.merge_from_file(\"./drive/My Drive/Colab Notebooks/detectron2_repo/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"wz\",)\n",
        "cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "# cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "cfg.MODEL.WEIGHTS = \"https://dl.fbaipublicfiles.com/detectron2/PointRend/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco/164955410/model_final_3c3198.pkl\"\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.02\n",
        "cfg.SOLVER.MAX_ITER = 500    # 300 iterations seems good enough, but you can certainly train longer\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE =256   # faster, and good enough for this toy dataset\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 28  # 28 classes (heng,shu....)\n",
        "# assert cfg.MODEL.ROI_HEADS.NUM_CLASSES == cfg.MODEL.POINT_HEAD.NUM_CLASSES\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVtTbR_A-WBq",
        "colab_type": "code",
        "outputId": "b6de9489-eb3f-4e32-e612-df4246c52b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#正式训练\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/30 16:02:17 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): PointRendROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=29, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=112, bias=True)\n",
            "    )\n",
            "    (mask_coarse_head): CoarseMaskHead(\n",
            "      (reduce_spatial_dim_conv): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (coarse_mask_fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (coarse_mask_fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (prediction): Linear(in_features=1024, out_features=1372, bias=True)\n",
            "    )\n",
            "    (mask_point_head): StandardPointHead(\n",
            "      (fc1): Conv1d(284, 256, kernel_size=(1,), stride=(1,))\n",
            "      (fc2): Conv1d(284, 256, kernel_size=(1,), stride=(1,))\n",
            "      (fc3): Conv1d(284, 256, kernel_size=(1,), stride=(1,))\n",
            "      (predictor): Conv1d(284, 28, kernel_size=(1,), stride=(1,))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[03/30 16:02:17 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from ./drive/My Drive/pic566_28class/images566.json\n",
            "\u001b[32m[03/30 16:02:17 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 566 images left.\n",
            "\u001b[32m[03/30 16:02:17 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/30 16:02:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.53 MiB\n",
            "\u001b[32m[03/30 16:02:17 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[03/30 16:02:17 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "'roi_heads.box_predictor.cls_score.weight' has shape (81, 1024) in the checkpoint but (29, 1024) in the model! Skipped.\n",
            "'roi_heads.box_predictor.cls_score.bias' has shape (81,) in the checkpoint but (29,) in the model! Skipped.\n",
            "'roi_heads.box_predictor.bbox_pred.weight' has shape (320, 1024) in the checkpoint but (112, 1024) in the model! Skipped.\n",
            "'roi_heads.box_predictor.bbox_pred.bias' has shape (320,) in the checkpoint but (112,) in the model! Skipped.\n",
            "'roi_heads.mask_coarse_head.prediction.weight' has shape (3920, 1024) in the checkpoint but (1372, 1024) in the model! Skipped.\n",
            "'roi_heads.mask_coarse_head.prediction.bias' has shape (3920,) in the checkpoint but (1372,) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.fc1.weight' has shape (256, 336, 1) in the checkpoint but (256, 284, 1) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.fc2.weight' has shape (256, 336, 1) in the checkpoint but (256, 284, 1) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.fc3.weight' has shape (256, 336, 1) in the checkpoint but (256, 284, 1) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.predictor.weight' has shape (80, 336, 1) in the checkpoint but (28, 284, 1) in the model! Skipped.\n",
            "'roi_heads.mask_point_head.predictor.bias' has shape (80,) in the checkpoint but (28,) in the model! Skipped.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/30 16:02:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[03/30 16:02:28 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 19  total_loss: 4.420  loss_cls: 2.230  loss_box_reg: 0.862  loss_mask: 0.686  loss_mask_point: 0.625  loss_rpn_cls: 0.101  loss_rpn_loc: 0.078  time: 0.5223  data_time: 0.0157  lr: 0.000400  max_mem: 2659M\n",
            "\u001b[32m[03/30 16:02:38 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 39  total_loss: 3.019  loss_cls: 1.029  loss_box_reg: 0.903  loss_mask: 0.591  loss_mask_point: 0.466  loss_rpn_cls: 0.024  loss_rpn_loc: 0.068  time: 0.5313  data_time: 0.0066  lr: 0.000799  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:02:49 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 59  total_loss: 2.484  loss_cls: 0.838  loss_box_reg: 0.868  loss_mask: 0.457  loss_mask_point: 0.301  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 0.5326  data_time: 0.0085  lr: 0.001199  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:03:00 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 79  total_loss: 2.007  loss_cls: 0.655  loss_box_reg: 0.666  loss_mask: 0.361  loss_mask_point: 0.290  loss_rpn_cls: 0.008  loss_rpn_loc: 0.059  time: 0.5361  data_time: 0.0067  lr: 0.001598  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:03:11 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 99  total_loss: 1.682  loss_cls: 0.523  loss_box_reg: 0.530  loss_mask: 0.281  loss_mask_point: 0.260  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 0.5396  data_time: 0.0067  lr: 0.001998  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:03:22 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 119  total_loss: 1.390  loss_cls: 0.372  loss_box_reg: 0.435  loss_mask: 0.226  loss_mask_point: 0.249  loss_rpn_cls: 0.011  loss_rpn_loc: 0.062  time: 0.5413  data_time: 0.0067  lr: 0.002398  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:03:33 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 139  total_loss: 1.468  loss_cls: 0.452  loss_box_reg: 0.457  loss_mask: 0.231  loss_mask_point: 0.258  loss_rpn_cls: 0.006  loss_rpn_loc: 0.063  time: 0.5444  data_time: 0.0066  lr: 0.002797  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:03:44 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 159  total_loss: 1.320  loss_cls: 0.417  loss_box_reg: 0.386  loss_mask: 0.214  loss_mask_point: 0.228  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 0.5450  data_time: 0.0063  lr: 0.003197  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:03:56 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 179  total_loss: 1.152  loss_cls: 0.294  loss_box_reg: 0.375  loss_mask: 0.195  loss_mask_point: 0.220  loss_rpn_cls: 0.005  loss_rpn_loc: 0.061  time: 0.5466  data_time: 0.0067  lr: 0.003596  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:04:07 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 199  total_loss: 1.209  loss_cls: 0.347  loss_box_reg: 0.367  loss_mask: 0.191  loss_mask_point: 0.191  loss_rpn_cls: 0.009  loss_rpn_loc: 0.067  time: 0.5469  data_time: 0.0075  lr: 0.003996  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:04:17 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 219  total_loss: 1.314  loss_cls: 0.403  loss_box_reg: 0.395  loss_mask: 0.198  loss_mask_point: 0.228  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 0.5463  data_time: 0.0081  lr: 0.004396  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:04:29 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 239  total_loss: 1.082  loss_cls: 0.258  loss_box_reg: 0.351  loss_mask: 0.172  loss_mask_point: 0.214  loss_rpn_cls: 0.009  loss_rpn_loc: 0.067  time: 0.5472  data_time: 0.0063  lr: 0.004795  max_mem: 2700M\n",
            "\u001b[32m[03/30 16:04:39 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 259  total_loss: 1.001  loss_cls: 0.271  loss_box_reg: 0.353  loss_mask: 0.166  loss_mask_point: 0.189  loss_rpn_cls: 0.008  loss_rpn_loc: 0.058  time: 0.5469  data_time: 0.0076  lr: 0.005195  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:04:51 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 279  total_loss: 1.024  loss_cls: 0.244  loss_box_reg: 0.336  loss_mask: 0.146  loss_mask_point: 0.176  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 0.5475  data_time: 0.0068  lr: 0.005594  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:05:02 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 299  total_loss: 0.966  loss_cls: 0.243  loss_box_reg: 0.337  loss_mask: 0.154  loss_mask_point: 0.175  loss_rpn_cls: 0.007  loss_rpn_loc: 0.059  time: 0.5477  data_time: 0.0072  lr: 0.005994  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:05:13 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 319  total_loss: 1.025  loss_cls: 0.253  loss_box_reg: 0.368  loss_mask: 0.148  loss_mask_point: 0.172  loss_rpn_cls: 0.008  loss_rpn_loc: 0.064  time: 0.5485  data_time: 0.0060  lr: 0.006394  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:05:24 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 339  total_loss: 1.028  loss_cls: 0.286  loss_box_reg: 0.378  loss_mask: 0.138  loss_mask_point: 0.179  loss_rpn_cls: 0.007  loss_rpn_loc: 0.081  time: 0.5498  data_time: 0.0077  lr: 0.006793  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:05:35 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 359  total_loss: 0.954  loss_cls: 0.220  loss_box_reg: 0.340  loss_mask: 0.134  loss_mask_point: 0.174  loss_rpn_cls: 0.005  loss_rpn_loc: 0.063  time: 0.5503  data_time: 0.0067  lr: 0.007193  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:05:46 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 379  total_loss: 0.968  loss_cls: 0.238  loss_box_reg: 0.352  loss_mask: 0.149  loss_mask_point: 0.188  loss_rpn_cls: 0.009  loss_rpn_loc: 0.059  time: 0.5502  data_time: 0.0072  lr: 0.007592  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:05:58 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 399  total_loss: 1.040  loss_cls: 0.276  loss_box_reg: 0.356  loss_mask: 0.145  loss_mask_point: 0.162  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 0.5509  data_time: 0.0074  lr: 0.007992  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:06:09 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 419  total_loss: 1.000  loss_cls: 0.246  loss_box_reg: 0.351  loss_mask: 0.130  loss_mask_point: 0.179  loss_rpn_cls: 0.010  loss_rpn_loc: 0.067  time: 0.5511  data_time: 0.0075  lr: 0.008392  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:06:20 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 439  total_loss: 0.980  loss_cls: 0.271  loss_box_reg: 0.366  loss_mask: 0.135  loss_mask_point: 0.159  loss_rpn_cls: 0.010  loss_rpn_loc: 0.056  time: 0.5519  data_time: 0.0065  lr: 0.008791  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:06:31 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 459  total_loss: 0.965  loss_cls: 0.249  loss_box_reg: 0.347  loss_mask: 0.127  loss_mask_point: 0.172  loss_rpn_cls: 0.009  loss_rpn_loc: 0.065  time: 0.5522  data_time: 0.0073  lr: 0.009191  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:06:43 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 479  total_loss: 0.893  loss_cls: 0.237  loss_box_reg: 0.313  loss_mask: 0.124  loss_mask_point: 0.161  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 0.5526  data_time: 0.0064  lr: 0.009590  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:06:55 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.976  loss_cls: 0.248  loss_box_reg: 0.358  loss_mask: 0.130  loss_mask_point: 0.159  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 0.5519  data_time: 0.0064  lr: 0.009990  max_mem: 2702M\n",
            "\u001b[32m[03/30 16:06:56 d2.engine.hooks]: \u001b[0mOverall training speed: 497 iterations in 0:04:34 (0.5530 s / it)\n",
            "\u001b[32m[03/30 16:06:56 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:37 (0:00:02 on hooks)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF",
        "colab_type": "text"
      },
      "source": [
        "Now, we perform inference with the trained model on the fruits_nuts dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM6RCjvB9vU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"wz\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO",
        "colab_type": "text"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM",
        "colab_type": "code",
        "outputId": "d0b9eb5b-954d-4a2b-dfb0-95e600bea763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(wanzhengdataset_dicts, 1):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=wanzheng_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels用于实例化可视化的不同颜色模式  IMAGE_BW：与IMAGE相同，但将所有不带遮罩的区域转换为灰度。仅适用于按实例绘制蒙版预测\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "    #如何输出单独的mask\n",
        "    "
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMwAAADMCAIAAACwQNulAAA58ElEQVR4nO19eXxU1dn/c86528xk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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=204x204 at 0x7F6C712FFD30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLH2qPSMgOSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "outputs[\"instances\"].pred_classes\n",
        "outputs[\"instances\"].pred_boxes\n",
        "outputs[\"instances\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bo0cypwllj",
        "colab_type": "code",
        "outputId": "306f13f0-fac2-4897-910d-07b08b30e5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "wanzheng_metadata"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metadata(evaluator_type='coco', image_root='./drive/My Drive/pic566_28class/images', json_file='./drive/My Drive/pic566_28class/images566.json', name='wz', thing_classes=['piezhe', 'heng', 'hengzhewangou', 'pie', 'na', 'shuwangou', 'henggou', 'shugou', 'hengzhegou', 'hengzhezhezhegou', 'hengpie', 'shu', 'shuzhezhegou', 'dian', 'wangou', 'ti', 'shuti', 'shuzhe', 'wogou', 'hengzhe', 'xiegou', 'hengzhezhepie', 'hengzhewan', 'piedian', 'shuzhepie', 'hengxiegou', 'hengzheti', 'shuwan'], thing_dataset_id_to_contiguous_id={1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvn2tueICLiE",
        "colab_type": "text"
      },
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API. This gives an AP of ~70%. Not bad!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Y_TQ6YCOWT",
        "colab_type": "code",
        "outputId": "59b1be27-2d54-4dfd-9f07-6f284d5d606f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"wz\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"wz\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "# another equivalent way is to use trainer.test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/29 09:01:38 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from ./drive/My Drive/pic566_28class/images566.json\n",
            "\u001b[32m[03/29 09:01:38 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/29 09:01:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.53 MiB\n",
            "\u001b[32m[03/29 09:01:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 images\n",
            "\u001b[32m[03/29 09:01:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. 0.0609 s / img. ETA=0:00:35\n",
            "\u001b[32m[03/29 09:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 85/566. 0.0623 s / img. ETA=0:00:32\n",
            "\u001b[32m[03/29 09:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 158/566. 0.0627 s / img. ETA=0:00:28\n",
            "\u001b[32m[03/29 09:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 229/566. 0.0629 s / img. ETA=0:00:23\n",
            "\u001b[32m[03/29 09:01:59 d2.evaluation.evaluator]: \u001b[0mInference done 304/566. 0.0627 s / img. ETA=0:00:18\n",
            "\u001b[32m[03/29 09:02:04 d2.evaluation.evaluator]: \u001b[0mInference done 374/566. 0.0632 s / img. ETA=0:00:13\n",
            "\u001b[32m[03/29 09:02:09 d2.evaluation.evaluator]: \u001b[0mInference done 447/566. 0.0631 s / img. ETA=0:00:08\n",
            "\u001b[32m[03/29 09:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 517/566. 0.0631 s / img. ETA=0:00:03\n",
            "\u001b[32m[03/29 09:02:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.195514 (0.069867 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/29 09:02:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:35 (0.063103 s / img per device, on 1 devices)\n",
            "\u001b[32m[03/29 09:02:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[03/29 09:02:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[03/29 09:02:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1fa900de22ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./output/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minference_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# another equivalent way is to use trainer.test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/evaluation/evaluator.py\u001b[0m in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator)\u001b[0m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;31m# An evaluator may return None when not in main process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# Replace it by an empty dict instead to make it easier for downstream code to handle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_box_proposals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"instances\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Copy so the caller can do whatever with results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36m_eval_predictions\u001b[0;34m(self, tasks, predictions)\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coco_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoco_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpt_oks_sigmas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kpt_oks_sigmas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 )\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_results\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# cocoapi does not handle empty results very well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36m_evaluate_predictions_on_coco\u001b[0;34m(coco_gt, coco_results, iou_type, kpt_oks_sigmas)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mcoco_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0mcoco_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoco_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;31m# Use the COCO default keypoint OKS sigmas unless overrides are specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36mloadRes\u001b[0;34m(self, resFile)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading and preparing results...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unicode' is not defined",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: Current TensorFlow version is 2.2.0-rc1. To use TF 1.x instead,\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\nyou run \"import tensorflow\".\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ6lYrCqLLLW",
        "colab_type": "text"
      },
      "source": [
        "## Benchmark inference speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxRHYcAC_Z0f",
        "colab_type": "code",
        "outputId": "1b93541d-ed1d-4fb5-ff55-1427970e38df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = predictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average(sec):0.07,fps:13.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFMOqBbWEh5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}