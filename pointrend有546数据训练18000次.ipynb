{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“成功得到AP[实验结果]”3000次",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiHanWang2Developer/data/blob/master/pointrend%E6%9C%89546%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%8318000%E6%AC%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR",
        "colab_type": "text"
      },
      "source": [
        "# [How to train Detectron2 with Custom COCO Datasets](https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/) | DLology\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "This notebook will help you get started with this framwork by training a instance segmentation model with your custom COCO datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bVqmEoGK4jf",
        "colab_type": "text"
      },
      "source": [
        "本文参考https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVDC4G20IuIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "5f8a5e3e-3818-4044-dca7-091c897baae1"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 20 03:37:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6db500c4-03fb-4d14-9c59-8e437cfeb714"
      },
      "source": [
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "# !pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.4+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.4.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (723.9MB)\n",
            "\u001b[K     |████████████████████████████████| 723.9MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.5.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.18.5)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torch-1.4.0+cu100 torchvision-0.5.0+cu100\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.20)\n",
            "Collecting pyyaml==5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44074 sha256=600bed44fea2cf1b89c76962348df38025bd4d38f9b848e50404fc1ad76cd497\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Collecting git+https://github.com/facebookresearch/fvcore.git\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-o8p_5muv\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-o8p_5muv\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1) (1.18.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1) (5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1) (4.41.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1) (7.0.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.1) (0.8.7)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.1-cp36-none-any.whl size=45053 sha256=adf6fbd1411ea3724c5ce6d1ac8c15e200b67b27f3e895941d2074515e5c1372\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z0tvvitx/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, portalocker, fvcore\n",
            "Successfully installed fvcore-0.1.1 portalocker-1.7.0 yacs-0.1.7\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-us71yxjk\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-us71yxjk\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (47.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.20)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=266988 sha256=2e41a9f5a345319fdc83165df39c7ac18011484a3ec7ef7856e46a622e4d41c5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fahr7jkb/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0.0\n",
            "    Uninstalling pycocotools-2.0.0:\n",
            "      Successfully uninstalled pycocotools-2.0.0\n",
            "Successfully installed pycocotools-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.4.0+cu100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeejixTmwEmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b63a7086-966e-40f6-d385-eaa5b5b7e2f0"
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
        "# clone the repo to access PointRend code. Use the same version as the installed detectron2\n",
        "!git clone --branch v0.1.1 https://github.com/facebookresearch/detectron2 detectron2_repo"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
            "Collecting detectron2\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/torch1.4/detectron2-0.1.3%2Bcu100-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 840kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.2.2)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.7)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: fvcore>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2) (7.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.29.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.34.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (47.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2) (5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (1.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.1.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n",
            "Installing collected packages: mock, detectron2\n",
            "Successfully installed detectron2-0.1.3+cu100 mock-4.0.2\n",
            "Cloning into 'detectron2_repo'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 5558 (delta 1), reused 3 (delta 1), pack-reused 5550\u001b[K\n",
            "Receiving objects: 100% (5558/5558), 2.56 MiB | 2.42 MiB/s, done.\n",
            "Resolving deltas: 100% (4005/4005), done.\n",
            "Note: checking out '401fd04cecec16f1ed0452eb936502d5d33a23be'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "# import PointRend project\n",
        "import sys; sys.path.insert(1, \"detectron2_repo/projects/PointRend\")\n",
        "from detectron2_repo.projects.PointRend import point_rend"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo",
        "colab_type": "text"
      },
      "source": [
        "# Train on a custom COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_",
        "colab_type": "text"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use [the fruits nuts segmentation dataset](https://github.com/Tony607/mmdetection_instance_segmentation_demo)\n",
        "which only has 3 classes: data, fig, and hazelnut.\n",
        "We'll train a segmentation model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that the COCO dataset does not have the \"data\", \"fig\" and \"hazelnut\" categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RhkndJ6JWqO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "d7b77089-f750-4de4-d620-531963d1a01b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW",
        "colab_type": "text"
      },
      "source": [
        "Register the fruits_nuts dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI-aG4sj3cV2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "下面 笔画数据集\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Retbdmc07rgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b9e7ae4-8800-4b9d-fda2-2b32403fc210"
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"L\", {}, \"./drive/My Drive/LGQ546/train546.json\", \"./drive/My Drive/LGQ546/imgs\")\n",
        "wanzheng_metadata = MetadataCatalog.get(\"L\")\n",
        "wanzhengdataset_dicts = DatasetCatalog.get(\"L\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[06/20 03:53:15 d2.data.datasets.coco]: \u001b[0mLoaded 546 images in COCO format from ./drive/My Drive/LGQ546/train546.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E",
        "colab_type": "text"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5JPh6Ur8FTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "07dc44a1-92eb-462e-f9c2-72a5da79487c"
      },
      "source": [
        "#笔画数据集\n",
        "import random\n",
        "for d in random.sample(wanzhengdataset_dicts, 1):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=wanzheng_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7FBFDFB167B8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA",
        "colab_type": "text"
      },
      "source": [
        "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the fruits_nuts dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqKpPAmApFOH",
        "colab_type": "text"
      },
      "source": [
        "## MaskRCNN模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d88692eb-b149-49ca-b262-f53293876648"
      },
      "source": [
        "# 创建MaskRCNN模型\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg1 = get_cfg()\n",
        "cfg1.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg1.DATASETS.TRAIN = (\"wz1100A\",)\n",
        "cfg1.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
        "cfg1.DATALOADER.NUM_WORKERS = 4\n",
        "cfg1.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "cfg1.SOLVER.IMS_PER_BATCH = 10\n",
        "cfg1.SOLVER.BASE_LR = 0.02\n",
        "cfg1.SOLVER.MAX_ITER = 8000    # 300 iterations seems good enough, but you can certainly train longer\n",
        "cfg1.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\n",
        "cfg1.MODEL.ROI_HEADS.NUM_CLASSES = 32 # 32 classes (data, fig, hazelnut)\n",
        "cfg1.OUTPUT_DIR='outputMRCNN'\n",
        "os.makedirs(cfg1.OUTPUT_DIR, exist_ok=True)\n",
        "MRCNNtrainer = DefaultTrainer(cfg1)\n",
        "MRCNNtrainer.resume_or_load(resume=False)\n",
        "MRCNNtrainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/19 12:04:59 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=33, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=128, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/19 12:04:59 d2.data.datasets.coco]: \u001b[0mLoaded 907 images in COCO format from ./drive/My Drive/pic32_907A/train.json\n",
            "\u001b[32m[04/19 12:04:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 907 images left.\n",
            "\u001b[32m[04/19 12:05:00 d2.data.common]: \u001b[0mSerializing 907 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/19 12:05:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.92 MiB\n",
            "\u001b[32m[04/19 12:05:00 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[04/19 12:05:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "model_final_f10217.pkl: 178MB [00:17, 10.4MB/s]                           \n",
            "'roi_heads.box_predictor.cls_score.weight' has shape (81, 1024) in the checkpoint but (33, 1024) in the model! Skipped.\n",
            "'roi_heads.box_predictor.cls_score.bias' has shape (81,) in the checkpoint but (33,) in the model! Skipped.\n",
            "'roi_heads.box_predictor.bbox_pred.weight' has shape (320, 1024) in the checkpoint but (128, 1024) in the model! Skipped.\n",
            "'roi_heads.box_predictor.bbox_pred.bias' has shape (320,) in the checkpoint but (128,) in the model! Skipped.\n",
            "'roi_heads.mask_head.predictor.weight' has shape (80, 256, 1, 1) in the checkpoint but (32, 256, 1, 1) in the model! Skipped.\n",
            "'roi_heads.mask_head.predictor.bias' has shape (80,) in the checkpoint but (32,) in the model! Skipped.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/19 12:05:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[04/19 12:05:38 d2.utils.events]: \u001b[0m eta: 2:19:04  iter: 19  total_loss: 4.240  loss_cls: 2.590  loss_box_reg: 0.822  loss_mask: 0.686  loss_rpn_cls: 0.109  loss_rpn_loc: 0.057  time: 1.0399  data_time: 0.0790  lr: 0.000400  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:05:58 d2.utils.events]: \u001b[0m eta: 2:16:21  iter: 39  total_loss: 2.554  loss_cls: 1.078  loss_box_reg: 0.839  loss_mask: 0.552  loss_rpn_cls: 0.022  loss_rpn_loc: 0.043  time: 1.0328  data_time: 0.0625  lr: 0.000799  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:06:19 d2.utils.events]: \u001b[0m eta: 2:18:36  iter: 59  total_loss: 2.159  loss_cls: 0.931  loss_box_reg: 0.815  loss_mask: 0.360  loss_rpn_cls: 0.019  loss_rpn_loc: 0.041  time: 1.0378  data_time: 0.0621  lr: 0.001199  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:06:40 d2.utils.events]: \u001b[0m eta: 2:19:03  iter: 79  total_loss: 1.894  loss_cls: 0.855  loss_box_reg: 0.768  loss_mask: 0.225  loss_rpn_cls: 0.011  loss_rpn_loc: 0.036  time: 1.0431  data_time: 0.0699  lr: 0.001598  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:07:01 d2.utils.events]: \u001b[0m eta: 2:18:44  iter: 99  total_loss: 1.634  loss_cls: 0.756  loss_box_reg: 0.657  loss_mask: 0.153  loss_rpn_cls: 0.012  loss_rpn_loc: 0.036  time: 1.0423  data_time: 0.0653  lr: 0.001998  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:07:22 d2.utils.events]: \u001b[0m eta: 2:18:31  iter: 119  total_loss: 1.399  loss_cls: 0.664  loss_box_reg: 0.550  loss_mask: 0.125  loss_rpn_cls: 0.009  loss_rpn_loc: 0.032  time: 1.0437  data_time: 0.0633  lr: 0.002398  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:07:43 d2.utils.events]: \u001b[0m eta: 2:18:15  iter: 139  total_loss: 1.131  loss_cls: 0.540  loss_box_reg: 0.429  loss_mask: 0.109  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0447  data_time: 0.0641  lr: 0.002797  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:08:04 d2.utils.events]: \u001b[0m eta: 2:17:57  iter: 159  total_loss: 1.076  loss_cls: 0.498  loss_box_reg: 0.416  loss_mask: 0.104  loss_rpn_cls: 0.008  loss_rpn_loc: 0.038  time: 1.0462  data_time: 0.0663  lr: 0.003197  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:08:25 d2.utils.events]: \u001b[0m eta: 2:17:33  iter: 179  total_loss: 0.985  loss_cls: 0.464  loss_box_reg: 0.358  loss_mask: 0.097  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0465  data_time: 0.0631  lr: 0.003596  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:08:46 d2.utils.events]: \u001b[0m eta: 2:17:11  iter: 199  total_loss: 0.843  loss_cls: 0.370  loss_box_reg: 0.340  loss_mask: 0.089  loss_rpn_cls: 0.008  loss_rpn_loc: 0.036  time: 1.0459  data_time: 0.0623  lr: 0.003996  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:09:07 d2.utils.events]: \u001b[0m eta: 2:16:48  iter: 219  total_loss: 0.790  loss_cls: 0.358  loss_box_reg: 0.329  loss_mask: 0.079  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 1.0456  data_time: 0.0656  lr: 0.004396  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:09:28 d2.utils.events]: \u001b[0m eta: 2:16:27  iter: 239  total_loss: 0.814  loss_cls: 0.371  loss_box_reg: 0.320  loss_mask: 0.084  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0459  data_time: 0.0648  lr: 0.004795  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:09:49 d2.utils.events]: \u001b[0m eta: 2:16:06  iter: 259  total_loss: 0.740  loss_cls: 0.329  loss_box_reg: 0.307  loss_mask: 0.081  loss_rpn_cls: 0.009  loss_rpn_loc: 0.031  time: 1.0455  data_time: 0.0629  lr: 0.005195  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:10:10 d2.utils.events]: \u001b[0m eta: 2:15:44  iter: 279  total_loss: 0.818  loss_cls: 0.363  loss_box_reg: 0.314  loss_mask: 0.082  loss_rpn_cls: 0.009  loss_rpn_loc: 0.026  time: 1.0461  data_time: 0.0681  lr: 0.005594  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:10:31 d2.utils.events]: \u001b[0m eta: 2:15:26  iter: 299  total_loss: 0.735  loss_cls: 0.307  loss_box_reg: 0.300  loss_mask: 0.077  loss_rpn_cls: 0.009  loss_rpn_loc: 0.038  time: 1.0469  data_time: 0.0678  lr: 0.005994  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:10:52 d2.utils.events]: \u001b[0m eta: 2:15:07  iter: 319  total_loss: 0.665  loss_cls: 0.279  loss_box_reg: 0.267  loss_mask: 0.069  loss_rpn_cls: 0.008  loss_rpn_loc: 0.030  time: 1.0476  data_time: 0.0628  lr: 0.006394  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:11:13 d2.utils.events]: \u001b[0m eta: 2:14:44  iter: 339  total_loss: 0.688  loss_cls: 0.276  loss_box_reg: 0.306  loss_mask: 0.076  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0475  data_time: 0.0669  lr: 0.006793  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:11:34 d2.utils.events]: \u001b[0m eta: 2:14:23  iter: 359  total_loss: 0.655  loss_cls: 0.269  loss_box_reg: 0.274  loss_mask: 0.073  loss_rpn_cls: 0.007  loss_rpn_loc: 0.030  time: 1.0468  data_time: 0.0678  lr: 0.007193  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:11:55 d2.utils.events]: \u001b[0m eta: 2:14:02  iter: 379  total_loss: 0.638  loss_cls: 0.247  loss_box_reg: 0.273  loss_mask: 0.067  loss_rpn_cls: 0.006  loss_rpn_loc: 0.037  time: 1.0468  data_time: 0.0665  lr: 0.007592  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:12:16 d2.utils.events]: \u001b[0m eta: 2:13:41  iter: 399  total_loss: 0.593  loss_cls: 0.249  loss_box_reg: 0.256  loss_mask: 0.066  loss_rpn_cls: 0.006  loss_rpn_loc: 0.028  time: 1.0465  data_time: 0.0674  lr: 0.007992  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:12:36 d2.utils.events]: \u001b[0m eta: 2:13:18  iter: 419  total_loss: 0.638  loss_cls: 0.261  loss_box_reg: 0.272  loss_mask: 0.066  loss_rpn_cls: 0.007  loss_rpn_loc: 0.031  time: 1.0461  data_time: 0.0630  lr: 0.008392  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:12:57 d2.utils.events]: \u001b[0m eta: 2:12:58  iter: 439  total_loss: 0.634  loss_cls: 0.225  loss_box_reg: 0.278  loss_mask: 0.063  loss_rpn_cls: 0.007  loss_rpn_loc: 0.030  time: 1.0463  data_time: 0.0647  lr: 0.008791  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:13:18 d2.utils.events]: \u001b[0m eta: 2:12:36  iter: 459  total_loss: 0.615  loss_cls: 0.243  loss_box_reg: 0.267  loss_mask: 0.066  loss_rpn_cls: 0.007  loss_rpn_loc: 0.026  time: 1.0462  data_time: 0.0637  lr: 0.009191  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:13:39 d2.utils.events]: \u001b[0m eta: 2:12:13  iter: 479  total_loss: 0.574  loss_cls: 0.229  loss_box_reg: 0.250  loss_mask: 0.060  loss_rpn_cls: 0.006  loss_rpn_loc: 0.035  time: 1.0456  data_time: 0.0622  lr: 0.009590  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:14:00 d2.utils.events]: \u001b[0m eta: 2:11:50  iter: 499  total_loss: 0.601  loss_cls: 0.224  loss_box_reg: 0.268  loss_mask: 0.064  loss_rpn_cls: 0.006  loss_rpn_loc: 0.030  time: 1.0455  data_time: 0.0736  lr: 0.009990  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:14:21 d2.utils.events]: \u001b[0m eta: 2:11:26  iter: 519  total_loss: 0.588  loss_cls: 0.215  loss_box_reg: 0.262  loss_mask: 0.064  loss_rpn_cls: 0.008  loss_rpn_loc: 0.033  time: 1.0454  data_time: 0.0652  lr: 0.010390  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:14:41 d2.utils.events]: \u001b[0m eta: 2:11:01  iter: 539  total_loss: 0.535  loss_cls: 0.205  loss_box_reg: 0.233  loss_mask: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.031  time: 1.0450  data_time: 0.0641  lr: 0.010789  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:15:02 d2.utils.events]: \u001b[0m eta: 2:10:42  iter: 559  total_loss: 0.550  loss_cls: 0.206  loss_box_reg: 0.235  loss_mask: 0.064  loss_rpn_cls: 0.007  loss_rpn_loc: 0.029  time: 1.0450  data_time: 0.0667  lr: 0.011189  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:15:23 d2.utils.events]: \u001b[0m eta: 2:10:21  iter: 579  total_loss: 0.524  loss_cls: 0.201  loss_box_reg: 0.239  loss_mask: 0.057  loss_rpn_cls: 0.007  loss_rpn_loc: 0.026  time: 1.0450  data_time: 0.0656  lr: 0.011588  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:15:44 d2.utils.events]: \u001b[0m eta: 2:10:00  iter: 599  total_loss: 0.527  loss_cls: 0.211  loss_box_reg: 0.227  loss_mask: 0.055  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 1.0448  data_time: 0.0658  lr: 0.011988  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:16:05 d2.utils.events]: \u001b[0m eta: 2:09:44  iter: 619  total_loss: 0.533  loss_cls: 0.194  loss_box_reg: 0.243  loss_mask: 0.058  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0453  data_time: 0.0693  lr: 0.012388  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:16:26 d2.utils.events]: \u001b[0m eta: 2:09:21  iter: 639  total_loss: 0.519  loss_cls: 0.184  loss_box_reg: 0.239  loss_mask: 0.058  loss_rpn_cls: 0.006  loss_rpn_loc: 0.029  time: 1.0449  data_time: 0.0664  lr: 0.012787  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:16:47 d2.utils.events]: \u001b[0m eta: 2:09:03  iter: 659  total_loss: 0.521  loss_cls: 0.189  loss_box_reg: 0.243  loss_mask: 0.053  loss_rpn_cls: 0.006  loss_rpn_loc: 0.029  time: 1.0453  data_time: 0.0641  lr: 0.013187  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:17:08 d2.utils.events]: \u001b[0m eta: 2:08:42  iter: 679  total_loss: 0.530  loss_cls: 0.202  loss_box_reg: 0.237  loss_mask: 0.055  loss_rpn_cls: 0.006  loss_rpn_loc: 0.028  time: 1.0450  data_time: 0.0614  lr: 0.013586  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:17:29 d2.utils.events]: \u001b[0m eta: 2:08:21  iter: 699  total_loss: 0.532  loss_cls: 0.196  loss_box_reg: 0.219  loss_mask: 0.052  loss_rpn_cls: 0.006  loss_rpn_loc: 0.025  time: 1.0451  data_time: 0.0691  lr: 0.013986  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:17:50 d2.utils.events]: \u001b[0m eta: 2:08:00  iter: 719  total_loss: 0.542  loss_cls: 0.193  loss_box_reg: 0.249  loss_mask: 0.057  loss_rpn_cls: 0.007  loss_rpn_loc: 0.029  time: 1.0452  data_time: 0.0669  lr: 0.014386  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:18:11 d2.utils.events]: \u001b[0m eta: 2:07:39  iter: 739  total_loss: 0.522  loss_cls: 0.176  loss_box_reg: 0.250  loss_mask: 0.053  loss_rpn_cls: 0.005  loss_rpn_loc: 0.028  time: 1.0454  data_time: 0.0626  lr: 0.014785  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:18:32 d2.utils.events]: \u001b[0m eta: 2:07:18  iter: 759  total_loss: 0.523  loss_cls: 0.195  loss_box_reg: 0.239  loss_mask: 0.057  loss_rpn_cls: 0.005  loss_rpn_loc: 0.030  time: 1.0455  data_time: 0.0647  lr: 0.015185  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:18:53 d2.utils.events]: \u001b[0m eta: 2:06:55  iter: 779  total_loss: 0.508  loss_cls: 0.186  loss_box_reg: 0.226  loss_mask: 0.052  loss_rpn_cls: 0.007  loss_rpn_loc: 0.028  time: 1.0454  data_time: 0.0637  lr: 0.015584  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:19:13 d2.utils.events]: \u001b[0m eta: 2:06:33  iter: 799  total_loss: 0.510  loss_cls: 0.186  loss_box_reg: 0.232  loss_mask: 0.056  loss_rpn_cls: 0.006  loss_rpn_loc: 0.030  time: 1.0451  data_time: 0.0646  lr: 0.015984  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:19:34 d2.utils.events]: \u001b[0m eta: 2:06:12  iter: 819  total_loss: 0.530  loss_cls: 0.188  loss_box_reg: 0.253  loss_mask: 0.052  loss_rpn_cls: 0.006  loss_rpn_loc: 0.031  time: 1.0451  data_time: 0.0658  lr: 0.016384  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:19:55 d2.utils.events]: \u001b[0m eta: 2:05:52  iter: 839  total_loss: 0.512  loss_cls: 0.174  loss_box_reg: 0.243  loss_mask: 0.054  loss_rpn_cls: 0.006  loss_rpn_loc: 0.028  time: 1.0452  data_time: 0.0678  lr: 0.016783  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:20:16 d2.utils.events]: \u001b[0m eta: 2:05:31  iter: 859  total_loss: 0.507  loss_cls: 0.189  loss_box_reg: 0.225  loss_mask: 0.055  loss_rpn_cls: 0.006  loss_rpn_loc: 0.030  time: 1.0451  data_time: 0.0656  lr: 0.017183  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:20:37 d2.utils.events]: \u001b[0m eta: 2:05:11  iter: 879  total_loss: 0.490  loss_cls: 0.172  loss_box_reg: 0.227  loss_mask: 0.049  loss_rpn_cls: 0.005  loss_rpn_loc: 0.026  time: 1.0451  data_time: 0.0684  lr: 0.017582  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:20:58 d2.utils.events]: \u001b[0m eta: 2:04:50  iter: 899  total_loss: 0.499  loss_cls: 0.182  loss_box_reg: 0.233  loss_mask: 0.051  loss_rpn_cls: 0.007  loss_rpn_loc: 0.025  time: 1.0452  data_time: 0.0639  lr: 0.017982  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:21:19 d2.utils.events]: \u001b[0m eta: 2:04:29  iter: 919  total_loss: 0.506  loss_cls: 0.184  loss_box_reg: 0.234  loss_mask: 0.052  loss_rpn_cls: 0.005  loss_rpn_loc: 0.028  time: 1.0454  data_time: 0.0680  lr: 0.018382  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:21:40 d2.utils.events]: \u001b[0m eta: 2:04:09  iter: 939  total_loss: 0.485  loss_cls: 0.175  loss_box_reg: 0.232  loss_mask: 0.050  loss_rpn_cls: 0.006  loss_rpn_loc: 0.028  time: 1.0455  data_time: 0.0700  lr: 0.018781  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:22:01 d2.utils.events]: \u001b[0m eta: 2:03:49  iter: 959  total_loss: 0.471  loss_cls: 0.179  loss_box_reg: 0.211  loss_mask: 0.050  loss_rpn_cls: 0.005  loss_rpn_loc: 0.030  time: 1.0457  data_time: 0.0653  lr: 0.019181  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:22:23 d2.utils.events]: \u001b[0m eta: 2:03:29  iter: 979  total_loss: 0.490  loss_cls: 0.179  loss_box_reg: 0.216  loss_mask: 0.049  loss_rpn_cls: 0.005  loss_rpn_loc: 0.029  time: 1.0461  data_time: 0.0647  lr: 0.019580  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:22:44 d2.utils.events]: \u001b[0m eta: 2:03:08  iter: 999  total_loss: 0.499  loss_cls: 0.170  loss_box_reg: 0.226  loss_mask: 0.050  loss_rpn_cls: 0.006  loss_rpn_loc: 0.024  time: 1.0462  data_time: 0.0652  lr: 0.019980  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:23:04 d2.utils.events]: \u001b[0m eta: 2:02:47  iter: 1019  total_loss: 0.506  loss_cls: 0.187  loss_box_reg: 0.229  loss_mask: 0.054  loss_rpn_cls: 0.007  loss_rpn_loc: 0.030  time: 1.0461  data_time: 0.0677  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:23:26 d2.utils.events]: \u001b[0m eta: 2:02:29  iter: 1039  total_loss: 0.495  loss_cls: 0.167  loss_box_reg: 0.234  loss_mask: 0.052  loss_rpn_cls: 0.006  loss_rpn_loc: 0.028  time: 1.0464  data_time: 0.0670  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:23:47 d2.utils.events]: \u001b[0m eta: 2:02:08  iter: 1059  total_loss: 0.505  loss_cls: 0.183  loss_box_reg: 0.220  loss_mask: 0.050  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0464  data_time: 0.0687  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:24:08 d2.utils.events]: \u001b[0m eta: 2:01:47  iter: 1079  total_loss: 0.481  loss_cls: 0.178  loss_box_reg: 0.208  loss_mask: 0.050  loss_rpn_cls: 0.006  loss_rpn_loc: 0.026  time: 1.0465  data_time: 0.0666  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:24:29 d2.utils.events]: \u001b[0m eta: 2:01:26  iter: 1099  total_loss: 0.447  loss_cls: 0.154  loss_box_reg: 0.216  loss_mask: 0.050  loss_rpn_cls: 0.005  loss_rpn_loc: 0.029  time: 1.0465  data_time: 0.0658  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:24:50 d2.utils.events]: \u001b[0m eta: 2:01:05  iter: 1119  total_loss: 0.463  loss_cls: 0.171  loss_box_reg: 0.218  loss_mask: 0.049  loss_rpn_cls: 0.007  loss_rpn_loc: 0.028  time: 1.0466  data_time: 0.0684  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:25:11 d2.utils.events]: \u001b[0m eta: 2:00:43  iter: 1139  total_loss: 0.453  loss_cls: 0.167  loss_box_reg: 0.205  loss_mask: 0.047  loss_rpn_cls: 0.007  loss_rpn_loc: 0.027  time: 1.0466  data_time: 0.0658  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:25:32 d2.utils.events]: \u001b[0m eta: 2:00:22  iter: 1159  total_loss: 0.445  loss_cls: 0.164  loss_box_reg: 0.196  loss_mask: 0.047  loss_rpn_cls: 0.006  loss_rpn_loc: 0.026  time: 1.0467  data_time: 0.0691  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:25:53 d2.utils.events]: \u001b[0m eta: 2:00:02  iter: 1179  total_loss: 0.424  loss_cls: 0.157  loss_box_reg: 0.201  loss_mask: 0.047  loss_rpn_cls: 0.006  loss_rpn_loc: 0.026  time: 1.0469  data_time: 0.0718  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:26:14 d2.utils.events]: \u001b[0m eta: 1:59:43  iter: 1199  total_loss: 0.446  loss_cls: 0.154  loss_box_reg: 0.202  loss_mask: 0.048  loss_rpn_cls: 0.004  loss_rpn_loc: 0.028  time: 1.0468  data_time: 0.0686  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:26:35 d2.utils.events]: \u001b[0m eta: 1:59:23  iter: 1219  total_loss: 0.420  loss_cls: 0.160  loss_box_reg: 0.189  loss_mask: 0.047  loss_rpn_cls: 0.004  loss_rpn_loc: 0.025  time: 1.0468  data_time: 0.0697  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:26:56 d2.utils.events]: \u001b[0m eta: 1:59:03  iter: 1239  total_loss: 0.437  loss_cls: 0.155  loss_box_reg: 0.192  loss_mask: 0.046  loss_rpn_cls: 0.004  loss_rpn_loc: 0.032  time: 1.0470  data_time: 0.0665  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:27:17 d2.utils.events]: \u001b[0m eta: 1:58:43  iter: 1259  total_loss: 0.446  loss_cls: 0.175  loss_box_reg: 0.196  loss_mask: 0.046  loss_rpn_cls: 0.005  loss_rpn_loc: 0.025  time: 1.0471  data_time: 0.0649  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:27:38 d2.utils.events]: \u001b[0m eta: 1:58:21  iter: 1279  total_loss: 0.414  loss_cls: 0.160  loss_box_reg: 0.183  loss_mask: 0.045  loss_rpn_cls: 0.006  loss_rpn_loc: 0.024  time: 1.0469  data_time: 0.0693  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:27:59 d2.utils.events]: \u001b[0m eta: 1:57:59  iter: 1299  total_loss: 0.428  loss_cls: 0.156  loss_box_reg: 0.189  loss_mask: 0.046  loss_rpn_cls: 0.005  loss_rpn_loc: 0.028  time: 1.0470  data_time: 0.0620  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:28:20 d2.utils.events]: \u001b[0m eta: 1:57:37  iter: 1319  total_loss: 0.417  loss_cls: 0.145  loss_box_reg: 0.183  loss_mask: 0.045  loss_rpn_cls: 0.006  loss_rpn_loc: 0.025  time: 1.0470  data_time: 0.0653  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:28:41 d2.utils.events]: \u001b[0m eta: 1:57:16  iter: 1339  total_loss: 0.432  loss_cls: 0.161  loss_box_reg: 0.191  loss_mask: 0.047  loss_rpn_cls: 0.005  loss_rpn_loc: 0.024  time: 1.0470  data_time: 0.0640  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:29:02 d2.utils.events]: \u001b[0m eta: 1:56:55  iter: 1359  total_loss: 0.425  loss_cls: 0.151  loss_box_reg: 0.190  loss_mask: 0.045  loss_rpn_cls: 0.006  loss_rpn_loc: 0.027  time: 1.0470  data_time: 0.0625  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:29:23 d2.utils.events]: \u001b[0m eta: 1:56:36  iter: 1379  total_loss: 0.423  loss_cls: 0.160  loss_box_reg: 0.192  loss_mask: 0.046  loss_rpn_cls: 0.007  loss_rpn_loc: 0.024  time: 1.0471  data_time: 0.0653  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:29:44 d2.utils.events]: \u001b[0m eta: 1:56:15  iter: 1399  total_loss: 0.436  loss_cls: 0.155  loss_box_reg: 0.196  loss_mask: 0.045  loss_rpn_cls: 0.006  loss_rpn_loc: 0.026  time: 1.0471  data_time: 0.0646  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:30:05 d2.utils.events]: \u001b[0m eta: 1:55:54  iter: 1419  total_loss: 0.413  loss_cls: 0.148  loss_box_reg: 0.182  loss_mask: 0.045  loss_rpn_cls: 0.004  loss_rpn_loc: 0.024  time: 1.0471  data_time: 0.0670  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:30:26 d2.utils.events]: \u001b[0m eta: 1:55:34  iter: 1439  total_loss: 0.409  loss_cls: 0.150  loss_box_reg: 0.192  loss_mask: 0.045  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 1.0471  data_time: 0.0685  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:30:46 d2.utils.events]: \u001b[0m eta: 1:55:12  iter: 1459  total_loss: 0.395  loss_cls: 0.143  loss_box_reg: 0.175  loss_mask: 0.044  loss_rpn_cls: 0.006  loss_rpn_loc: 0.023  time: 1.0470  data_time: 0.0662  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:31:07 d2.utils.events]: \u001b[0m eta: 1:54:52  iter: 1479  total_loss: 0.404  loss_cls: 0.143  loss_box_reg: 0.185  loss_mask: 0.043  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.0470  data_time: 0.0703  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:31:28 d2.utils.events]: \u001b[0m eta: 1:54:31  iter: 1499  total_loss: 0.382  loss_cls: 0.136  loss_box_reg: 0.175  loss_mask: 0.044  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.0471  data_time: 0.0627  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:31:49 d2.utils.events]: \u001b[0m eta: 1:54:11  iter: 1519  total_loss: 0.413  loss_cls: 0.160  loss_box_reg: 0.177  loss_mask: 0.044  loss_rpn_cls: 0.005  loss_rpn_loc: 0.024  time: 1.0471  data_time: 0.0635  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:32:11 d2.utils.events]: \u001b[0m eta: 1:53:51  iter: 1539  total_loss: 0.400  loss_cls: 0.146  loss_box_reg: 0.176  loss_mask: 0.044  loss_rpn_cls: 0.005  loss_rpn_loc: 0.024  time: 1.0473  data_time: 0.0657  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:32:32 d2.utils.events]: \u001b[0m eta: 1:53:32  iter: 1559  total_loss: 0.383  loss_cls: 0.139  loss_box_reg: 0.176  loss_mask: 0.045  loss_rpn_cls: 0.006  loss_rpn_loc: 0.027  time: 1.0473  data_time: 0.0624  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:32:53 d2.utils.events]: \u001b[0m eta: 1:53:12  iter: 1579  total_loss: 0.385  loss_cls: 0.138  loss_box_reg: 0.168  loss_mask: 0.044  loss_rpn_cls: 0.004  loss_rpn_loc: 0.024  time: 1.0473  data_time: 0.0612  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:33:13 d2.utils.events]: \u001b[0m eta: 1:52:50  iter: 1599  total_loss: 0.385  loss_cls: 0.140  loss_box_reg: 0.172  loss_mask: 0.044  loss_rpn_cls: 0.007  loss_rpn_loc: 0.027  time: 1.0472  data_time: 0.0663  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:33:34 d2.utils.events]: \u001b[0m eta: 1:52:26  iter: 1619  total_loss: 0.372  loss_cls: 0.143  loss_box_reg: 0.160  loss_mask: 0.042  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.0471  data_time: 0.0662  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:33:55 d2.utils.events]: \u001b[0m eta: 1:52:06  iter: 1639  total_loss: 0.399  loss_cls: 0.131  loss_box_reg: 0.176  loss_mask: 0.046  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.0472  data_time: 0.0630  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:34:16 d2.utils.events]: \u001b[0m eta: 1:51:44  iter: 1659  total_loss: 0.387  loss_cls: 0.147  loss_box_reg: 0.166  loss_mask: 0.044  loss_rpn_cls: 0.005  loss_rpn_loc: 0.027  time: 1.0473  data_time: 0.0632  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:34:37 d2.utils.events]: \u001b[0m eta: 1:51:23  iter: 1679  total_loss: 0.379  loss_cls: 0.131  loss_box_reg: 0.170  loss_mask: 0.044  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.0473  data_time: 0.0639  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:34:58 d2.utils.events]: \u001b[0m eta: 1:51:04  iter: 1699  total_loss: 0.371  loss_cls: 0.133  loss_box_reg: 0.163  loss_mask: 0.044  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 1.0473  data_time: 0.0656  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:35:19 d2.utils.events]: \u001b[0m eta: 1:50:44  iter: 1719  total_loss: 0.378  loss_cls: 0.141  loss_box_reg: 0.162  loss_mask: 0.043  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.0473  data_time: 0.0642  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:35:40 d2.utils.events]: \u001b[0m eta: 1:50:24  iter: 1739  total_loss: 0.367  loss_cls: 0.128  loss_box_reg: 0.168  loss_mask: 0.042  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.0474  data_time: 0.0653  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:36:01 d2.utils.events]: \u001b[0m eta: 1:50:03  iter: 1759  total_loss: 0.367  loss_cls: 0.134  loss_box_reg: 0.162  loss_mask: 0.043  loss_rpn_cls: 0.005  loss_rpn_loc: 0.026  time: 1.0473  data_time: 0.0641  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:36:23 d2.utils.events]: \u001b[0m eta: 1:49:43  iter: 1779  total_loss: 0.361  loss_cls: 0.133  loss_box_reg: 0.159  loss_mask: 0.045  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 1.0475  data_time: 0.0653  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:36:44 d2.utils.events]: \u001b[0m eta: 1:49:23  iter: 1799  total_loss: 0.362  loss_cls: 0.123  loss_box_reg: 0.165  loss_mask: 0.042  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 1.0475  data_time: 0.0700  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:37:04 d2.utils.events]: \u001b[0m eta: 1:49:01  iter: 1819  total_loss: 0.352  loss_cls: 0.132  loss_box_reg: 0.161  loss_mask: 0.041  loss_rpn_cls: 0.005  loss_rpn_loc: 0.025  time: 1.0474  data_time: 0.0616  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:37:25 d2.utils.events]: \u001b[0m eta: 1:48:40  iter: 1839  total_loss: 0.350  loss_cls: 0.124  loss_box_reg: 0.153  loss_mask: 0.042  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.0475  data_time: 0.0677  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:37:46 d2.utils.events]: \u001b[0m eta: 1:48:20  iter: 1859  total_loss: 0.357  loss_cls: 0.131  loss_box_reg: 0.161  loss_mask: 0.042  loss_rpn_cls: 0.004  loss_rpn_loc: 0.025  time: 1.0473  data_time: 0.0614  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:38:07 d2.utils.events]: \u001b[0m eta: 1:47:59  iter: 1879  total_loss: 0.360  loss_cls: 0.138  loss_box_reg: 0.157  loss_mask: 0.043  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.0474  data_time: 0.0649  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:38:28 d2.utils.events]: \u001b[0m eta: 1:47:37  iter: 1899  total_loss: 0.354  loss_cls: 0.131  loss_box_reg: 0.147  loss_mask: 0.042  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.0473  data_time: 0.0665  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:38:49 d2.utils.events]: \u001b[0m eta: 1:47:16  iter: 1919  total_loss: 0.352  loss_cls: 0.135  loss_box_reg: 0.154  loss_mask: 0.044  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 1.0474  data_time: 0.0600  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:39:10 d2.utils.events]: \u001b[0m eta: 1:46:55  iter: 1939  total_loss: 0.360  loss_cls: 0.135  loss_box_reg: 0.157  loss_mask: 0.042  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.0474  data_time: 0.0669  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:39:31 d2.utils.events]: \u001b[0m eta: 1:46:33  iter: 1959  total_loss: 0.368  loss_cls: 0.135  loss_box_reg: 0.161  loss_mask: 0.041  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 1.0473  data_time: 0.0649  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:39:52 d2.utils.events]: \u001b[0m eta: 1:46:11  iter: 1979  total_loss: 0.353  loss_cls: 0.129  loss_box_reg: 0.157  loss_mask: 0.043  loss_rpn_cls: 0.004  loss_rpn_loc: 0.026  time: 1.0474  data_time: 0.0647  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:40:13 d2.utils.events]: \u001b[0m eta: 1:45:50  iter: 1999  total_loss: 0.364  loss_cls: 0.141  loss_box_reg: 0.155  loss_mask: 0.040  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.0474  data_time: 0.0653  lr: 0.020000  max_mem: 8731M\n",
            "\u001b[32m[04/19 12:40:34 d2.utils.events]: \u001b[0m eta: 1:45:26  iter: 2019  total_loss: 0.349  loss_cls: 0.118  loss_box_reg: 0.154  loss_mask: 0.041  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.0472  data_time: 0.0667  lr: 0.020000  max_mem: 8731M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4mZwgPUoXv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 创建MaskRCNN模型\n",
        "cfg1.MODEL.WEIGHTS = os.path.join(cfg1.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg1.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg1.DATASETS.TEST = (\"wz\", )\n",
        "MRCNNpredictor = DefaultPredictor(cfg1)\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(wanzhengdataset_dicts, 1):    \n",
        "    # im = cv2.imread(d[\"file_name\"])\n",
        "    im = cv2.imread('/content/drive/My Drive/pic566_28class/images/000545.jpg')\n",
        "    outputs = MRCNNpredictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=wanzheng_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels用于实例化可视化的不同颜色模式  IMAGE_BW：与IMAGE相同，但将所有不带遮罩的区域转换为灰度。仅适用于按实例绘制蒙版预测\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "    #如何输出单独的mask\n",
        "    masks=np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks)#[n,256,256]n为笔画数\n",
        "    count=0\n",
        "    for mask in masks:\n",
        "      mask=mask.astype(\"uint8\")#mask从[false,flase]到[00001100]\n",
        "      mask=mask*255       #变成二值图\n",
        "      cv2_imshow(mask)\n",
        "\n",
        "      count=count+1\n",
        "      # file_path=\"/content/\"+str(count)+\".jpg\"\n",
        "      # cv2.imwrite(file_path,mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaXRLPfqtJjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir outputMRCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyUCDYnqHOKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"wz\", cfg1, False, output_dir=\"./outputMRCNN/\")#output_dir可选的输出目录，用于转储数据集上预测的所有结果。转储包含两个文件 \"instance_predictions.pth\" “ coco_instances_results.json”\n",
        "val_loader = build_detection_test_loader(cfg1, \"wz\")\n",
        "inference_on_dataset(MRCNNtrainer.model, val_loader, evaluator)\n",
        "# another equivalent way is to use trainer.test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdCjVuZ7gSxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = MRCNNpredictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSV_XTI1tJTw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ9_YjV7o7xk",
        "colab_type": "text"
      },
      "source": [
        "## Pointrend模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEuB2wY_8kCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e28e81cf-8ae9-4263-e77a-5e5161389468"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "\n",
        "# Add PointRend-specific config\n",
        "point_rend.add_pointrend_config(cfg)\n",
        "cfg.MODEL.POINT_HEAD.NUM_CLASSES = 28 #修改POINT_HEAD.NUM_CLASSES 32 默认值为80\n",
        "\n",
        "\n",
        "cfg.merge_from_file(\"detectron2_repo/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"L\",)\n",
        "cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "\n",
        "cfg.MODEL.WEIGHTS = \"https://dl.fbaipublicfiles.com/detectron2/PointRend/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco/164955410/model_final_3c3198.pkl\" # initialize from model zoo\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 10\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 18000    # 3000 iterations seems good enough, but you can certainly train longer\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE =128   # faster, and good enough for this toy dataset\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 28  # 28 classes (heng,shu....)\n",
        "cfg.OUTPUT_DIR= '/content/drive/My Drive/lgq18000'\n",
        "\n",
        "#正式训练\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[06/20 03:53:59 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): PointRendROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=29, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=112, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[06/20 03:53:59 d2.data.datasets.coco]: \u001b[0mLoaded 546 images in COCO format from ./drive/My Drive/LGQ546/train546.json\n",
            "\u001b[32m[06/20 03:53:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 546 images left.\n",
            "\u001b[32m[06/20 03:53:59 d2.data.build]: \u001b[0mDistribution of instances among all 28 categories:\n",
            "\u001b[36m|   category    | #instances   |  category  | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
            "|      pie      | 719          |    dian    | 745          |      shu      | 845          |\n",
            "|     heng      | 1488         |   shuti    | 28           |    shuzhe     | 37           |\n",
            "|    hengzhe    | 286          |   shugou   | 88           |    henggou    | 59           |\n",
            "|      ti       | 85           |   wogou    | 15           |    xiegou     | 29           |\n",
            "|  hengzhegou   | 115          |     na     | 140          |    hengpie    | 46           |\n",
            "|    shuwan     | 12           |   piezhe   | 61           |    wangou     | 28           |\n",
            "| shuzhezhegou  | 4            |  piedian   | 16           | hengzhezhepie | 15           |\n",
            "|   shuwangou   | 16           | hengxiegou | 3            | hengpiewangou | 6            |\n",
            "|  hengzhezhe   | 1            | shuzhezhe  | 1            |  hengzhewan   | 1            |\n",
            "| hengzhewangou | 1            |            |              |               |              |\n",
            "|     total     | 4890         |            |              |               |              |\u001b[0m\n",
            "\u001b[32m[06/20 03:53:59 d2.data.common]: \u001b[0mSerializing 546 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[06/20 03:53:59 d2.data.common]: \u001b[0mSerialized dataset takes 3.10 MiB\n",
            "\u001b[32m[06/20 03:53:59 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[06/20 03:53:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "model_final_3c3198.pkl: 241MB [00:21, 11.5MB/s]                           \n",
            "Unable to load 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (29, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (29,) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (112, 1024) in the model!\n",
            "Unable to load 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (112,) in the model!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[06/20 03:54:22 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[06/20 03:54:58 d2.utils.events]: \u001b[0m eta: 8:23:52  iter: 19  total_loss: 4.938  loss_cls: 3.151  loss_box_reg: 0.853  loss_rpn_cls: 0.850  loss_rpn_loc: 0.107  time: 1.7498  data_time: 1.1827  lr: 0.000005  max_mem: 7143M\n",
            "\u001b[32m[06/20 03:55:28 d2.utils.events]: \u001b[0m eta: 7:47:51  iter: 39  total_loss: 4.590  loss_cls: 2.927  loss_box_reg: 0.888  loss_rpn_cls: 0.644  loss_rpn_loc: 0.111  time: 1.6253  data_time: 0.8872  lr: 0.000010  max_mem: 7143M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-HbfLDNHojH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF",
        "colab_type": "text"
      },
      "source": [
        "Now, we perform inference with the trained model on the fruits_nuts dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM6RCjvB9vU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir  output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCp8IQ-aF53h",
        "colab_type": "text"
      },
      "source": [
        "## inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"L\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO",
        "colab_type": "text"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d91baf9f-4859-451b-f57c-2e4dff71fd4f"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(wanzhengdataset_dicts, 1):    \n",
        "#     im = cv2.imread(d[\"file_name\"])\n",
        "    im = cv2.imread('/content/drive/My Drive/pic566_28class/images/000545.jpg') #使用活字 的图片\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=wanzheng_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels用于实例化可视化的不同颜色模式  IMAGE_BW：与IMAGE相同，但将所有不带遮罩的区域转换为灰度。仅适用于按实例绘制蒙版预测\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "    #如何输出单独的mask\n",
        "    masks=np.asarray(outputs[\"instances\"].to(\"cpu\").pred_masks)#[n,256,256]n为笔画数\n",
        "    count=0\n",
        "    for mask in masks:\n",
        "      mask=mask.astype(\"uint8\")#mask从[false,flase]到[00001100]\n",
        "      mask=mask*255       #变成二值图\n",
        "      cv2_imshow(mask)\n",
        "\n",
        "      count=count+1\n",
        "      file_path=\"/content/\"+str(count)+\".jpg\"\n",
        "      cv2.imwrite(file_path,mask)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=204x204 at 0x7F172692C390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAABn0lEQVR4nO3Y3XKCMBAG0KXT939lemHHFgUFsjTZ6TlX/gyy+xmTmAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOCvTb0LiJj3VTHfH6XW/Jn5YReaF48TIxhgBETMb6qYn17JK3uAAI63H5FXeP8AXk8B691HRFbpI88BL5q/vZ0RQfcRcOtyeurmTfff2ssfJICIX6Xs6/3horMGCiCmY73/XNVipABOamuhawDtzUdEYw+9Akjq/aaliT7L4LH2p+OX7DfyPmDxxU4XJTBkAKtD+qIEuswBJ3f3mwnUmwMW+q7Ene4+n7n31gho6qHTCOi+/7r76F1Au7Yw6wfQOJjKB9D6Y6oeQPNkUiiAtUWgfTItFMCKhMWkdgAJSgeQsZuoHEDKbqpyACnqBPC0CORsp+sE8Cjp70TdAJKUDSDr/2TZALJUDSDtQKFMAFcdi5cJYCnvRKloAHkE0LuAnZZTQOKZapUALlMygMxD9SIBXLUIlglg2nzSqkgA1/n3AQAAAAAAAAAAAAAAAAAAAABQ3RcYBiNsZusI3AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F187E4DF0B8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAABKklEQVR4nO3ZSw6CQBAFwDHx/lfGBZhoYkwj3fOJVSvjAvo9UGBoDQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmN1t9AA5tpfP5yItX8D28dt4rJUL+Jz9EA22aAFfs++CyZYrIBD9EIu2UgHx7LtQtkUKOJt9Fwk3fQG/RT8E0t2vbL/WpehhkxbQJ3xrcxbQL32bq4CuwZ+GFzAk9YtxV4H65FPeB2y3uuA/ZelWQEXujOFrCyg52rkj1xSQH7zsQOVuOD14/S80cQ9p6bv+MQ+/D3gz4KKcucvqB7cS48+AwQ/kqbs/fwqMX45IniB7xa5e9hyRBmbJ3lqrGCZltb6fiomuvqwBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+yANb7BsvN+7t0wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F187E4DF208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAABcElEQVR4nO3ZS27CQBAFwCbK/a9MVhEJ2Iag6Y+jqhUL5On3GBvLjgAAAAAAAAAAAIB/69I9wJHr94fEKT/yDr3Q9fr8O286RwGJFZylgB/nw1qTrwEPkTOGPc8OiJzzYPAO2E67euBT7YCI9btgbgG7Qdc2MLaAg5hLG/hcebB18m587s3cAXX5R/4LPIu/dOaBO6A0/8Ad8CT/6oGnFXAcP2HaYQUc5c8ZdVIB9ekzD/xnLfEHFbCfP3fEIQV0xZ9SwG7+/PEmFNAYf0IBe/GLJusuYCd+3Vi9BbTH7y1gQPzOAkbE7ytgSPyuAmqeeL+kY9Exv37Pqpvx+y5F5Stv5e/8Kyp+LF74uPdFpQ9Ft15rXZpvxgoXf0zffR8eUThDycv+NxSNcRd/SPiIolF+xR8UPqJmnFv+YeEjKnfAwPAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQI4vo60wKhahpd8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F187E4DF048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAAyElEQVR4nO3WwQ6CMBAE0Gr4/1/Gix4wxDQ4uIt57wYHMjs0bccAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAICv3aoDTFm3j8nQ7QtY914GUzcuYHf0p1zsjgV8mvwllntJfShgZvC4FivgyOSp4KUroOSXv6kroMP0o66AJuOPca8OcFBs77poAbm9u9MxOCd8bl2hgFOP6oYF/PZqUl9Ai6sYAAAAAAAAAAAAAAAA/+MBuX8JLN9QQLIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F187E4DF208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAABuUlEQVR4nO3X0U4CMRAF0K7x/38ZH4wEBHTabkLm5pwXNWkIc/dOhTEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5i6Xd7+DVR+nvErb8U8KoPH8JzWgsTMC6FyAMwK4jDHGsf8672EFtl+h9QJowH4A3wVoewVsB9B8AbYDaD//SXdA3w3YDKB/AfYC+Jm/cQH8G9wJIGABtgK4zt95AzYCiHj+7oD1AEIKsBzAzfytrwArsBhAygKsBnA7f+8NWAsg5/m7A5YCuCtA8w1YCSBpAfZXoHsBFgLIKsB8AGHz765A+w2YDiCtALMBxM0/GcDv+ftvgE+CUwHkLcBcAA/zB2zATACJz3+Mz+rBzPHrDXg2f8IGFBuQ+vhHsQHB85cCeDF/xAZUAkh+/pUAsuff+CicsQGFAEIGfcWXof+PZFdguQEpsVQCSJn1KXdA5VByBVYbEJNJLYCYcR+5A2rHciugAcVzx59/NqYB734D71YOIKf09zSgfPJ48XtzEw0ImvrG0gokRTETQNLcV1MNOO5+ZJhbgajRv03eAceITAEAAAAAAAAAAAAAAIjyBWCBJZKpxsxnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F187E4DF048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAABgUlEQVR4nO3cy07CABRF0Wr8/1+uEx8UGTDx7mtca6ROONmh0kDpcQAAAAAAAAAAAAAAAAAAAAAA8He91AM+nEe0ZUeA8+un8T0bApyX34YXLQhw3v9hdNPr5IM96UeR37QxwGiBlQEmCywI0P4bWhDgkbmnwNIAczYESI+BDQFSAtQDjuPRMTB3VKwIUBKgHlDbGWDwhXFngEEC1ANqKwNMnhuvDDBJgHpAbWOAf/+u8CgB6gE1AeoBtYUBZt8jXRhglgD1gNq+AMMfk+wLMGxFgNErIu6sCFASoB5QE6AecG/6YoF1AaYJUA+obQhQngetCJASoB5QE6AeUNsWYPyq0W0BxglQD6gJUA+4ngnPXzm/IEBLgHpATYB6wEXw7aFdAQIC1ANqAtQDan2AmzPh4iukfYCYAPWAmgD1gJoA9YAbyY0U8gDpR8PHggA1AeoB35p7qSwK0BCgHlB7qwd8WnBjQwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWeQcuig2vxnfrdwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F187E4DF208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAABM0lEQVR4nO3bsYpCURADUPX///lZWKmFKLwkyDmNzcLMhtxBFvZyAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAICY6+kTjtCcH6UCyMz6QTKAzLwv3cLzjuPzz0SlA5iLIB/AmPMDeH/1UxXQgPNHzB3+JxoQmDFdAQ1oL9AWCWD5DWhAY+jSN6FMAMNvwBNoL9AmgMyY3SOgAe0F2gTQXqAtFcDsFew0YOi7sCfQXqBNAKlBq1dQA9oLtAmgvUBbLoDRK6gB7QXaBNBeoC0YwOYV1ID2Am0C6Izd+ZNQMoDJK+gJtBdoE0B7gbZoAItXUAPaC7RlAxh8AxrQXqBNANlx15fPPg2oTN0pQDyAoV/9odKAuRSixv5zFAAAAAAAAAAAAIB/dQey3w2CUk8EmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F187E4DF048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAA+UlEQVR4nO3XQQrCMBAF0Oj97xw3IoiKMDOL/vDertCW9CczSdcCAAAAAAAAAAAAgCPdis/t5vOXUfqA/X4ZHcJ94B17/7/nsiZWQP1FF1Ab99cpz4xgogSeMiuhFsCPyU5MoLgCzkmgWgLHJDDYA9ZagQmUA/jV89MSqK+AzF3vQ6MEzmgDnR5wO2ER9JrgAQk0d4H8BLrbYHwC7XNAegL9g1B4AgMnwewEJo7C0dvhzL9AcAJjQ38dAMPCGPsbTK2D0WHvuPkHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKY8AHPAEDbEXMBeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F187E4DF208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bo0cypwllj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "63854c5a-44ac-4b93-bf72-aa1099085a8e"
      },
      "source": [
        "wanzheng_metadata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metadata(evaluator_type='coco', image_root='./drive/My Drive/pic566_28class/images', json_file='./drive/My Drive/pic566_28class/images566.json', name='wzInfer', thing_classes=['piezhe', 'heng', 'hengzhewangou', 'pie', 'na', 'shuwangou', 'henggou', 'shugou', 'hengzhegou', 'hengzhezhezhegou', 'hengpie', 'shu', 'shuzhezhegou', 'dian', 'wangou', 'ti', 'shuti', 'shuzhe', 'wogou', 'hengzhe', 'xiegou', 'hengzhezhepie', 'hengzhewan', 'piedian', 'shuzhepie', 'hengxiegou', 'hengzheti', 'shuwan'], thing_dataset_id_to_contiguous_id={1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvn2tueICLiE",
        "colab_type": "text"
      },
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API. This gives an AP of ~70%. Not bad!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGKtdLlNFZk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e13ab192-5d9a-45fb-b227-c17fa18723eb"
      },
      "source": [
        "print(cfg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('wzInfer',)\n",
            "  TRAIN: ('wz',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: bitmask\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  POINT_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    COARSE_PRED_EACH_LAYER: True\n",
            "    FC_DIM: 256\n",
            "    IMPORTANCE_SAMPLE_RATIO: 0.75\n",
            "    IN_FEATURES: ('p2',)\n",
            "    NAME: StandardPointHead\n",
            "    NUM_CLASSES: 32\n",
            "    NUM_FC: 3\n",
            "    OVERSAMPLE_RATIO: 3\n",
            "    SUBDIVISION_NUM_POINTS: 784\n",
            "    SUBDIVISION_STEPS: 5\n",
            "    TRAIN_NUM_POINTS: 196\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 50\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: True\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: PointRendROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 32\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.5\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    IN_FEATURES: ('p2',)\n",
            "    NAME: CoarseMaskHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    NUM_FC: 2\n",
            "    OUTPUT_SIDE_RESOLUTION: 7\n",
            "    POINT_HEAD_ON: True\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: ./output/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  BASE_LR: 0.00025\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 10\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 10000\n",
            "  MOMENTUM: 0.9\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0.0001\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWn8_HF-GBD3",
        "colab_type": "text"
      },
      "source": [
        "## **检验效果---AP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Y_TQ6YCOWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec5ddf85-4e77-4867-be4d-e060cf37941a"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"wz\", cfg, False, output_dir=\"./output/\")#output_dir可选的输出目录，用于转储数据集上预测的所有结果。转储包含两个文件 \"instance_predictions.pth\" “ coco_instances_results.json”\n",
        "val_loader = build_detection_test_loader(cfg, \"wz\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "# another equivalent way is to use trainer.test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/19 11:57:14 d2.data.datasets.coco]: \u001b[0mLoaded 680 images in COCO format from ./drive/My Drive/pic32/train.json\n",
            "\u001b[32m[04/19 11:57:14 d2.data.build]: \u001b[0mDistribution of instances among all 32 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "|    piezhe     | 76           |     heng      | 1025         | hengzhewangou | 21           |\n",
            "|      pie      | 828          |      na       | 200          |   shuwangou   | 56           |\n",
            "|    henggou    | 47           |    shugou     | 109          |   shuzhezhe   | 11           |\n",
            "|      shu      | 600          |    hengzhe    | 173          |  hengzhegou   | 157          |\n",
            "| hengzhezhezhe | 5            | hengzhezhez.. | 9            |    hengpie    | 67           |\n",
            "|  hengzhezhe   | 11           | shuzhezhegou  | 18           |     dian      | 328          |\n",
            "|    wangou     | 22           |      ti       | 130          |     shuti     | 23           |\n",
            "|    shuzhe     | 29           |     wogou     | 15           |    xiegou     | 17           |\n",
            "| hengzhezhepie | 22           |  hengzhewan   | 7            |    piedian    | 12           |\n",
            "|   shuzhepie   | 2            |  hengxiegou   | 9            |   hengzheti   | 3            |\n",
            "|    shuwan     | 7            | hengpiewangou | 7            |               |              |\n",
            "|     total     | 4046         |               |              |               |              |\u001b[0m\n",
            "\u001b[32m[04/19 11:57:14 d2.data.common]: \u001b[0mSerializing 680 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/19 11:57:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.66 MiB\n",
            "\u001b[32m[04/19 11:57:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 680 images\n",
            "\u001b[32m[04/19 11:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/680. 0.0655 s / img. ETA=0:00:50\n",
            "\u001b[32m[04/19 11:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 58/680. 0.0671 s / img. ETA=0:01:04\n",
            "\u001b[32m[04/19 11:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 108/680. 0.0679 s / img. ETA=0:00:58\n",
            "\u001b[32m[04/19 11:57:34 d2.evaluation.evaluator]: \u001b[0mInference done 156/680. 0.0678 s / img. ETA=0:00:53\n",
            "\u001b[32m[04/19 11:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 206/680. 0.0680 s / img. ETA=0:00:48\n",
            "\u001b[32m[04/19 11:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 257/680. 0.0683 s / img. ETA=0:00:43\n",
            "\u001b[32m[04/19 11:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 315/680. 0.0682 s / img. ETA=0:00:36\n",
            "\u001b[32m[04/19 11:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 370/680. 0.0682 s / img. ETA=0:00:30\n",
            "\u001b[32m[04/19 11:58:00 d2.evaluation.evaluator]: \u001b[0mInference done 424/680. 0.0683 s / img. ETA=0:00:24\n",
            "\u001b[32m[04/19 11:58:05 d2.evaluation.evaluator]: \u001b[0mInference done 470/680. 0.0682 s / img. ETA=0:00:20\n",
            "\u001b[32m[04/19 11:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 524/680. 0.0686 s / img. ETA=0:00:15\n",
            "\u001b[32m[04/19 11:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 581/680. 0.0686 s / img. ETA=0:00:09\n",
            "\u001b[32m[04/19 11:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 633/680. 0.0687 s / img. ETA=0:00:04\n",
            "\u001b[32m[04/19 11:58:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:05.945664 (0.097697 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/19 11:58:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:46 (0.068884 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/19 11:58:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/19 11:58:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[04/19 11:58:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.95s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.45s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.864\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.957\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.953\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.625\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.846\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.877\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.857\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.923\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.923\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.723\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.910\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.918\n",
            "\u001b[32m[04/19 11:58:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 86.448 | 95.650 | 95.305 | 62.454 | 84.610 | 87.695 |\n",
            "\u001b[32m[04/19 11:58:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP      | category         | AP     | category      | AP     |\n",
            "|:--------------|:--------|:-----------------|:-------|:--------------|:-------|\n",
            "| piezhe        | 86.598  | heng             | 79.168 | hengzhewangou | 92.922 |\n",
            "| pie           | 85.485  | na               | 89.301 | shuwangou     | 84.726 |\n",
            "| henggou       | 80.048  | shugou           | 86.858 | shuzhezhe     | 96.823 |\n",
            "| shu           | 77.905  | hengzhe          | 78.492 | hengzhegou    | 85.307 |\n",
            "| hengzhezhezhe | 100.000 | hengzhezhezhegou | 78.564 | hengpie       | 91.395 |\n",
            "| hengzhezhe    | 94.554  | shuzhezhegou     | 91.283 | dian          | 74.517 |\n",
            "| wangou        | 78.006  | ti               | 86.556 | shuti         | 80.599 |\n",
            "| shuzhe        | 81.658  | wogou            | 90.211 | xiegou        | 89.867 |\n",
            "| hengzhezhepie | 91.625  | hengzhewan       | 94.042 | piedian       | 89.711 |\n",
            "| shuzhepie     | 90.000  | hengxiegou       | 86.661 | hengzheti     | 71.119 |\n",
            "| shuwan        | 92.129  | hengpiewangou    | 90.212 |               |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=2.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.44s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.822\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.956\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.924\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.368\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.804\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.814\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.881\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.901\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.819\n",
            "\u001b[32m[04/19 11:58:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 82.199 | 95.574 | 92.363 | 36.765 | 80.406 | 81.954 |\n",
            "\u001b[32m[04/19 11:58:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category      | AP     | category         | AP     | category      | AP     |\n",
            "|:--------------|:-------|:-----------------|:-------|:--------------|:-------|\n",
            "| piezhe        | 79.870 | heng             | 80.815 | hengzhewangou | 80.891 |\n",
            "| pie           | 83.985 | na               | 87.715 | shuwangou     | 80.033 |\n",
            "| henggou       | 80.417 | shugou           | 87.043 | shuzhezhe     | 89.901 |\n",
            "| shu           | 83.417 | hengzhe          | 78.198 | hengzhegou    | 79.444 |\n",
            "| hengzhezhezhe | 90.000 | hengzhezhezhegou | 76.590 | hengpie       | 84.645 |\n",
            "| hengzhezhe    | 84.554 | shuzhezhegou     | 77.863 | dian          | 76.200 |\n",
            "| wangou        | 82.191 | ti               | 85.788 | shuti         | 76.942 |\n",
            "| shuzhe        | 69.457 | wogou            | 91.700 | xiegou        | 82.887 |\n",
            "| hengzhezhepie | 78.165 | hengzhewan       | 92.554 | piedian       | 77.875 |\n",
            "| shuzhepie     | 90.000 | hengxiegou       | 76.158 | hengzheti     | 66.119 |\n",
            "| shuwan        | 88.939 | hengpiewangou    | 90.000 |               |        |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 86.44821402532902,\n",
              "               'AP-dian': 74.51679407539574,\n",
              "               'AP-heng': 79.16831918641024,\n",
              "               'AP-henggou': 80.04840441275499,\n",
              "               'AP-hengpie': 91.39495832830366,\n",
              "               'AP-hengpiewangou': 90.2121640735502,\n",
              "               'AP-hengxiegou': 86.66116611661167,\n",
              "               'AP-hengzhe': 78.49187895177208,\n",
              "               'AP-hengzhegou': 85.30686159841957,\n",
              "               'AP-hengzheti': 71.11881188118811,\n",
              "               'AP-hengzhewan': 94.04172560113155,\n",
              "               'AP-hengzhewangou': 92.92209484106306,\n",
              "               'AP-hengzhezhe': 94.55445544554455,\n",
              "               'AP-hengzhezhepie': 91.62530869791784,\n",
              "               'AP-hengzhezhezhe': 100.0,\n",
              "               'AP-hengzhezhezhegou': 78.56435643564356,\n",
              "               'AP-na': 89.30098745098854,\n",
              "               'AP-pie': 85.48464326083361,\n",
              "               'AP-piedian': 89.7112211221122,\n",
              "               'AP-piezhe': 86.59821861051617,\n",
              "               'AP-shu': 77.90482161810843,\n",
              "               'AP-shugou': 86.85774368648175,\n",
              "               'AP-shuti': 80.59896575864484,\n",
              "               'AP-shuwan': 92.12871287128714,\n",
              "               'AP-shuwangou': 84.72620211582954,\n",
              "               'AP-shuzhe': 81.65770687313325,\n",
              "               'AP-shuzhepie': 90.0,\n",
              "               'AP-shuzhezhe': 96.82268226822683,\n",
              "               'AP-shuzhezhegou': 91.28280685211378,\n",
              "               'AP-ti': 86.55638033175144,\n",
              "               'AP-wangou': 78.00594177064765,\n",
              "               'AP-wogou': 90.2112211221122,\n",
              "               'AP-xiegou': 89.86729345203427,\n",
              "               'AP50': 95.65004750579703,\n",
              "               'AP75': 95.30509628487071,\n",
              "               'APl': 87.69500349137013,\n",
              "               'APm': 84.61009531931043,\n",
              "               'APs': 62.45427182323149}),\n",
              "             ('segm',\n",
              "              {'AP': 82.19867148971515,\n",
              "               'AP-dian': 76.19973924014151,\n",
              "               'AP-heng': 80.8147423320504,\n",
              "               'AP-henggou': 80.41735791942646,\n",
              "               'AP-hengpie': 84.64492588371583,\n",
              "               'AP-hengpiewangou': 90.0,\n",
              "               'AP-hengxiegou': 76.15841584158416,\n",
              "               'AP-hengzhe': 78.19822359901248,\n",
              "               'AP-hengzhegou': 79.44439577376122,\n",
              "               'AP-hengzheti': 66.11881188118811,\n",
              "               'AP-hengzhewan': 92.55445544554455,\n",
              "               'AP-hengzhewangou': 80.89083950411847,\n",
              "               'AP-hengzhezhe': 84.55445544554455,\n",
              "               'AP-hengzhezhepie': 78.16549550917824,\n",
              "               'AP-hengzhezhezhe': 90.0,\n",
              "               'AP-hengzhezhezhegou': 76.58965896589659,\n",
              "               'AP-na': 87.71510296807482,\n",
              "               'AP-pie': 83.98473266053045,\n",
              "               'AP-piedian': 77.87541254125412,\n",
              "               'AP-piezhe': 79.87000561323012,\n",
              "               'AP-shu': 83.41650870173332,\n",
              "               'AP-shugou': 87.04253752177611,\n",
              "               'AP-shuti': 76.94224374667179,\n",
              "               'AP-shuwan': 88.93917963224894,\n",
              "               'AP-shuwangou': 80.03335715038389,\n",
              "               'AP-shuzhe': 69.45692047791005,\n",
              "               'AP-shuzhepie': 90.0,\n",
              "               'AP-shuzhezhe': 89.9009900990099,\n",
              "               'AP-shuzhezhegou': 77.86319346220337,\n",
              "               'AP-ti': 85.7879845852224,\n",
              "               'AP-wangou': 82.19103577024369,\n",
              "               'AP-wogou': 91.6996699669967,\n",
              "               'AP-xiegou': 82.8870954322323,\n",
              "               'AP50': 95.57374151360874,\n",
              "               'AP75': 92.3626040676941,\n",
              "               'APl': 81.95436934997848,\n",
              "               'APm': 80.40630017449347,\n",
              "               'APs': 36.76488073506232})])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ6lYrCqLLLW",
        "colab_type": "text"
      },
      "source": [
        "## Benchmark inference speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxRHYcAC_Z0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ece8f4ac-7b22-4a9f-aec5-565ebceda266"
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = predictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average(sec):0.08,fps:12.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFMOqBbWEh5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}